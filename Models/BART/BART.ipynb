{"cells":[{"cell_type":"markdown","metadata":{"id":"zmjViG0g8ndp"},"source":["## Multi-class classification using BART"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJ3fMlsk8z8U"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALj5fHwu9zWE"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11728,"status":"ok","timestamp":1709594710608,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"Neds00-S8ndt"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import BartTokenizer, BartForSequenceClassification, TrainingArguments, Trainer\n","import torch\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score\n","from transformers import TrainerCallback\n","import os\n","import shutil\n","import re\n","import time\n","from pathlib import Path\n","#[3.328079168300429e-05, 0.11210091359531205, 5, 9, 21]\n","def main_model(file_name, ext, type):\n","\n","    path_type = \"Balanced\" if type == 1 else \"Unbalanced\"\n","\n","    current_file_path = Path(__file__).parent\n","    path_to_project = current_file_path.parents[1]\n","\n","    df = pd.read_excel(f\"{path_to_project}/Data/Datasets/{path_type}/{file_name}.{ext}\")\n","\n","    results_dir = f\"{path_to_project}/Models/BART/Output/{path_type}/{file_name}\"\n","    dump_dir = results_dir+\"/Dump\"\n","\n","    if os.path.isdir(results_dir):\n","        shutil.rmtree(results_dir)\n","\n","    os.mkdir(results_dir)\n","    os.mkdir(dump_dir)\n","\n","    df = df[df['review'].notna() & (df['review'] != '')]\n","    # Select the text and label columns\n","    df['review'] = df['review'].str.replace('[^\\x20-\\x7E]', '', regex=True)\n","    X = df['review'].values\n","    y = df['label'].values\n","\n","    X_train_CV, X_test_full, y_train_CV, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","\n","    # Encode the labels to a numeric format\n","    label_encoder = LabelEncoder()\n","    y_train_CV_encoded = label_encoder.fit_transform(y_train_CV)\n","    y_test_full_encoded = label_encoder.transform(y_test_full)\n","\n","\n","    tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","    # Tokenization function\n","    def tokenize_function(texts):\n","        return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n","\n","    loss_logging_callback = LossLoggingCallback()\n","\n","    # Stratified K-Fold Cross-Validation\n","    n_splits = 5\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    # Variables to accumulate scores\n","    best_accuracy = 0\n","    best_model = None\n","    accuracy_scores = []\n","    metrics_df = pd.DataFrame()\n","\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(X_train_CV, y_train_CV_encoded)):\n","        print(f\"Fold {fold+1}/{n_splits}\")\n","        start_time = time.time()\n","        # Split the data\n","        X_train, X_val = X_train_CV[train_index], X_train_CV[val_index]\n","        y_train, y_val = y_train_CV_encoded[train_index], y_train_CV_encoded[val_index]\n","\n","\n","        # Tokenize the data\n","        train_encodings = tokenize_function(X_train.tolist())\n","        val_encodings = tokenize_function(X_val.tolist())\n","\n","        # Create dataset objects\n","        train_dataset = ReviewDataset(train_encodings, y_train)\n","        val_dataset = ReviewDataset(val_encodings, y_val)\n","\n","        # Initialize the model for each fold\n","        model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=len(label_encoder.classes_))\n","\n","        # Define training arguments for each fold, adjust hyperparameters as needed\n","        training_args = TrainingArguments(\n","            output_dir=f\"{dump_dir}/res\",\n","            num_train_epochs=5,\n","            per_device_train_batch_size=9,\n","            per_device_eval_batch_size=21,\n","            warmup_steps=500,\n","            weight_decay=0.11210091359531205,\n","            logging_dir=f\"{dump_dir}/logs\",\n","            logging_strategy=\"epoch\",\n","            evaluation_strategy=\"epoch\",\n","            learning_rate=3.328079168300429e-05,\n","            max_grad_norm=1.0,\n","            load_best_model_at_end=True,\n","            metric_for_best_model=\"accuracy\",\n","            save_strategy=\"epoch\",\n","            save_total_limit=2,\n","            lr_scheduler_type='linear'\n","        )\n","\n","        # Initialize Trainer\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=val_dataset,\n","            compute_metrics=compute_metrics,\n","            callbacks=[loss_logging_callback]\n","        )\n","\n","        # Train\n","        trainer.train()\n","\n","        loss_logging_callback.save_logs_to_excel(f\"{results_dir}/fold_loss.xlsx\")\n","\n","        # Evaluate\n","        results = trainer.evaluate()\n","        accuracy_scores.append(results['eval_accuracy'])\n","\n","        if results['eval_accuracy'] > best_accuracy:\n","            best_accuracy = results['eval_accuracy']\n","            best_model = model  # Assign the best model\n","\n","        # Get predictions and true labels\n","        predictions = trainer.predict(val_dataset)\n","        pred_labels = get_pred_labels(predictions)\n","        true_labels = y_val\n","\n","        # Calculate accuracy\n","        accuracy = accuracy_score(true_labels, pred_labels)\n","        label_names = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n","\n","        # Calculate precision, recall, and F1-score\n","        report_dict = classification_report(true_labels, pred_labels, output_dict=True, zero_division=0, target_names=label_names)\n","        # avg_metrics = report_dict['weighted avg']  # Use 'macro avg' or 'weighted avg' based on your preference\n","        end_time = time.time()\n","        # Append the metrics for this fold to the DataFrame\n","        metrics_df = metrics_df.append({\n","            ('Fold', ''): fold + 1,\n","            ('Accuracy', ''): accuracy,\n","            ('Train Time', ''): str(end_time - start_time)+\" s\",\n","            ('Bug Report', 'P'): report_dict['bug report']['precision'],\n","            ('Bug Report', 'R'): report_dict['bug report']['recall'],\n","            ('Bug Report', 'F1'): report_dict['bug report']['f1-score'],\n","            ('Feature Request', 'P'): report_dict['feature request']['precision'],\n","            ('Feature Request', 'R'): report_dict['feature request']['recall'],\n","            ('Feature Request', 'F1'): report_dict['feature request']['f1-score'],\n","            ('Rating', 'P'): report_dict['rating']['precision'],\n","            ('Rating', 'R'): report_dict['rating']['recall'],\n","            ('Rating', 'F1'): report_dict['rating']['f1-score'],\n","            ('User Experience', 'P'): report_dict['user experience']['precision'],\n","            ('User Experience', 'R'): report_dict['user experience']['recall'],\n","            ('User Experience', 'F1'): report_dict['user experience']['f1-score']\n","        }, ignore_index=True)\n","\n","    # Save the DataFrame to a CSV file after completing all folds\n","    metrics_df.columns = pd.MultiIndex.from_tuples([(c,) if isinstance(c, str) else c for c in metrics_df.columns])\n","    metrics_df.to_excel(f\"{results_dir}/fold_metrics.xlsx\", index=True)\n","\n","    # Evaluate the best model on the test set\n","    test_encodings = tokenize_function(X_test_full.tolist())\n","    test_dataset = ReviewDataset(test_encodings, y_test_full_encoded)\n","    test_trainer = Trainer(model=best_model)\n","    test_results = test_trainer.predict(test_dataset)\n","    test_predictions = get_pred_labels(test_results)\n","    test_accuracy = accuracy_score(y_test_full_encoded, test_predictions)\n","\n","    label_names_full = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n","\n","    # Calculate precision, recall, and F1-score\n","    report_dict_full = classification_report(y_test_full_encoded, test_predictions, output_dict=True, zero_division=0, target_names=label_names_full)\n","\n","    full_metrics_df = pd.DataFrame()\n","\n","    full_metrics_df = full_metrics_df.append({\n","            ('Accuracy', ''): test_accuracy,\n","            ('Bug Report', 'P'): report_dict_full['bug report']['precision'],\n","            ('Bug Report', 'R'): report_dict_full['bug report']['recall'],\n","            ('Bug Report', 'F1'): report_dict_full['bug report']['f1-score'],\n","            ('Feature Request', 'P'): report_dict_full['feature request']['precision'],\n","            ('Feature Request', 'R'): report_dict_full['feature request']['recall'],\n","            ('Feature Request', 'F1'): report_dict_full['feature request']['f1-score'],\n","            ('Rating', 'P'): report_dict_full['rating']['precision'],\n","            ('Rating', 'R'): report_dict_full['rating']['recall'],\n","            ('Rating', 'F1'): report_dict_full['rating']['f1-score'],\n","            ('User Experience', 'P'): report_dict_full['user experience']['precision'],\n","            ('User Experience', 'R'): report_dict_full['user experience']['recall'],\n","            ('User Experience', 'F1'): report_dict_full['user experience']['f1-score']\n","        }, ignore_index=True)\n","\n","    full_metrics_df.columns = pd.MultiIndex.from_tuples([(c,) if isinstance(c, str) else c for c in full_metrics_df.columns])\n","    full_metrics_df.to_excel(f\"{results_dir}/metrics_results_full_test.xlsx\", index=True)\n","\n","    print(f\"Test Accuracy: {test_accuracy}\")\n","\n","    # Generate and print the classification report\n","    print(classification_report(y_test_full_encoded, test_predictions, target_names=label_encoder.classes_, zero_division=0))\n","\n","    shutil.rmtree(dump_dir)\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    # If logits are wrapped in a tuple, unwrap them. Otherwise, leave as is.\n","    if isinstance(logits, tuple):  # Adjust this line if the structure is different\n","        logits = logits[0]\n","    predictions = np.argmax(logits, axis=-1)\n","    return {\"accuracy\": accuracy_score(predictions, labels)}\n","\n","def get_pred_labels(trainer_prediction):\n","    logits = trainer_prediction.predictions\n","    labels = trainer_prediction.label_ids\n","    # Check if the logits are wrapped in a tuple (this is usually not the case with predict(), but included for completeness)\n","    if isinstance(logits, tuple):\n","        logits = logits[0]\n","    # Compute the predicted class indices\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    return predictions\n","\n","# Custom dataset class\n","class ReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","class LossLoggingCallback(TrainerCallback):\n","    \"\"\"A custom callback to log training and validation loss.\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.log_history = []\n","        self.log_train_loss_history = []\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        # This method captures both training and evaluation logs, so it's more general than on_epoch_end\n","        if logs is not None:\n","            # Capture both training and evaluation steps\n","            if 'loss' in logs:  # Indicates a training step\n","                self.log_train_loss_history.append({\n","                    'epoch': state.epoch,\n","                    'training_loss': logs.get('loss'),\n","                })\n","            elif 'eval_loss' in logs:  # Indicates an evaluation step\n","                # Make sure to capture the last training loss as well\n","                last_training_loss = self.log_train_loss_history[-1]['training_loss'] if self.log_train_loss_history else None\n","                self.log_history.append({\n","                    'epoch': state.epoch,\n","                    'training_loss': last_training_loss,  # Include last known training loss for reference\n","                    'validation_loss': logs.get('eval_loss'),\n","                    'eval_runtime':logs.get('eval_runtime')\n","                })\n","\n","    def save_logs_to_excel(self, file_name):\n","        \"\"\"Save the recorded logs to a Excel file.\"\"\"\n","        pd.DataFrame(self.log_history).to_excel(file_name, index=False)\n","\n","__file__ = \"/content/drive/MyDrive/FinalProject/Models/BART/BART.ipynb\"\n","current_file_path = Path(__file__).parent\n","path_to_project = current_file_path.parents[1]\n","\n","directory_path_multi = path_to_project / 'Data' / 'Datasets' / 'Balanced'\n","\n","files_multi = [(file.name, file.stat().st_size)\n","               for file in directory_path_multi.iterdir()\n","               if file.is_file() and not file.name.startswith('.')]\n","\n","files_multi.sort(key=lambda x: x[1])\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Running each dataset on the model separately due to storage constraints"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["004af2b73f0c426c8c4839b62148d3bc","4904c5d93edf418eb366a0cf874ff23c","ddc96509c8f24f298f74be370a3d9faf","d8ddc8ef4dc3499fb1b198096b6cd3c8","f7f0f613881e44a1a5e79bf8dafe4d17","ca362e1730d9441283a7efe24fa8404b","155cddcefaba432f9d6d57e868c64a15","8edc9f07113d4b94983d6b72043888ca","283988d928a847c892d9d07baff221dd","30c9ed9d93564932a9d0316d8f52ed9c","dea4ac9ac1d9424f87fad1fc9312c863","00a6052def7e4197a5c5b1b0b45803ab","f360a218292348f4b6814bce5f353d47","b6cffae2d83b418898ff8276655ecedb","2edbccc5200240f2a81d3c61a2cbe04d","7cdb4d0ccaf643a599e55874f2c12ceb","6352bb5c22d74d5a943648793b01eccf","107fc1d57c554098b322b07013534152","c2993dedbd0b4805adfbe6d400cbce2d","ef8b68ae53724392b0f075cf4f9ad445","ba11b77eb5d749248154d79ab86142b6","6eec4062eb154eaf892b9c03e960e63b","2c5b85e076a74ba780cae05d42368f8a","da35f86b6de2423497d60f48d39fddde","17ba83d2fec24b92bce7cf78081c8462","3c004a13999347ecbba15ddc11e8e203","85e413a91a904490a6de0bee98510aec","f31de05417254d68baae9567a0272df1","111aac1c928c434aa170ef74f09197fd","2d5ba59379fb4d68b4c8cda77fcffb6d","c6890bcadefb4ed89ed58db06dfbd070","44b695f128824178b7f75dbf6e331d37","312f1e25adc64740ae264250cecab3fe","42cdc65822b34fa1a34b0e57a7f32670","0fecc90cafd9478b801ea2e65197765e","3c776864e4bd46e6b5e35d6de57b34c7","5b9947ebccf643179a41a0348bc50877","7fe6f45983f44762b789586392bbd905","4e676320994543f0b7da6329de484c89","7a00f7bc8c9746febd867a9e36553f16","f179040323834b8a82dd10283036e6da","f4fd6031f51d4a94864b57b28c07610c","125fc0db75e14a1a8afde77445cd7408","a7b0f54872e64eb085fe44d46fb0e584","74ee73a51d614ff8bd895fe86781e10c","cf1802e72e8444ce8b4b83120f4248cf","89b4e6584a15447594eb60a5b0748745","8a1ea3a2f289416190e83b076359bc13","38d04fcd21024fe4b3a9bf127dc5d945","168ac6fb08aa45c28df2323810795b89","58514e3c432f409f8c92bbb0b2973407","7c5fa0df1f0641fc856f52f33c1baba7","0854e8b45bc54b3b89c27e7e157910af","ad674b1e578a49548952386fccdf875e","41c4b423c432490c8fb1ec0d00f6928d"]},"executionInfo":{"elapsed":1334945,"status":"ok","timestamp":1709502320695,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"zEcg2GTS9tpz","outputId":"993dffb0-3ad4-46b6-99b4-5bacecb2efe7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_balanced_4000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"004af2b73f0c426c8c4839b62148d3bc","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00a6052def7e4197a5c5b1b0b45803ab","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c5b85e076a74ba780cae05d42368f8a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42cdc65822b34fa1a34b0e57a7f32670","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold 1/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74ee73a51d614ff8bd895fe86781e10c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.133700</td>\n","      <td>0.716097</td>\n","      <td>0.715625</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.751500</td>\n","      <td>0.716639</td>\n","      <td>0.737500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.543200</td>\n","      <td>0.661820</td>\n","      <td>0.776563</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.318700</td>\n","      <td>0.721166</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.193600</td>\n","      <td>0.719498</td>\n","      <td>0.828125</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.134900</td>\n","      <td>0.713338</td>\n","      <td>0.732812</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.734700</td>\n","      <td>0.644920</td>\n","      <td>0.754687</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.495700</td>\n","      <td>0.700848</td>\n","      <td>0.776563</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.302200</td>\n","      <td>1.059623</td>\n","      <td>0.764062</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.184300</td>\n","      <td>0.976820</td>\n","      <td>0.767188</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:49, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.132700</td>\n","      <td>0.832237</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.743600</td>\n","      <td>0.725027</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.531800</td>\n","      <td>0.769006</td>\n","      <td>0.726562</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.295700</td>\n","      <td>0.952885</td>\n","      <td>0.778125</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.172000</td>\n","      <td>1.041649</td>\n","      <td>0.764062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:49, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.138400</td>\n","      <td>0.839027</td>\n","      <td>0.681250</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.744300</td>\n","      <td>0.679819</td>\n","      <td>0.743750</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.501400</td>\n","      <td>0.707213</td>\n","      <td>0.768750</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.305100</td>\n","      <td>0.884496</td>\n","      <td>0.771875</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.149700</td>\n","      <td>1.030085</td>\n","      <td>0.779687</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.123000</td>\n","      <td>0.659818</td>\n","      <td>0.757812</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.727000</td>\n","      <td>0.734013</td>\n","      <td>0.715625</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.519100</td>\n","      <td>0.728083</td>\n","      <td>0.781250</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.315200</td>\n","      <td>0.750375</td>\n","      <td>0.779687</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.170300</td>\n","      <td>0.830405</td>\n","      <td>0.800000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.78125\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.83      0.88      0.85       200\n","feature request       0.76      0.82      0.79       200\n","         rating       0.82      0.69      0.75       200\n","user experience       0.72      0.74      0.73       200\n","\n","       accuracy                           0.78       800\n","      macro avg       0.78      0.78      0.78       800\n","   weighted avg       0.78      0.78      0.78       800\n","\n","Now doing: dataset_balanced_8000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2846' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:08, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.980900</td>\n","      <td>0.866072</td>\n","      <td>0.704688</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.580500</td>\n","      <td>0.580987</td>\n","      <td>0.792969</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.353000</td>\n","      <td>0.586236</td>\n","      <td>0.832031</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.212700</td>\n","      <td>0.480798</td>\n","      <td>0.885156</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='18' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18/61 00:00 < 00:02, 17.95 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.980900</td>\n","      <td>0.866072</td>\n","      <td>0.704688</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.580500</td>\n","      <td>0.580987</td>\n","      <td>0.792969</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.353000</td>\n","      <td>0.586236</td>\n","      <td>0.832031</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.212700</td>\n","      <td>0.480798</td>\n","      <td>0.885156</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.117100</td>\n","      <td>0.522662</td>\n","      <td>0.891406</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:16, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.982600</td>\n","      <td>0.712930</td>\n","      <td>0.733594</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.579100</td>\n","      <td>0.624048</td>\n","      <td>0.760156</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.334900</td>\n","      <td>0.616757</td>\n","      <td>0.835938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.183300</td>\n","      <td>0.659899</td>\n","      <td>0.860938</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.089600</td>\n","      <td>0.709505</td>\n","      <td>0.872656</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.984700</td>\n","      <td>0.651592</td>\n","      <td>0.747656</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.571700</td>\n","      <td>0.516288</td>\n","      <td>0.810156</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.326100</td>\n","      <td>0.518493</td>\n","      <td>0.867188</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.195600</td>\n","      <td>0.582946</td>\n","      <td>0.886719</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.094600</td>\n","      <td>0.637755</td>\n","      <td>0.893750</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.980400</td>\n","      <td>0.619845</td>\n","      <td>0.763281</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.605700</td>\n","      <td>0.549060</td>\n","      <td>0.795312</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.370300</td>\n","      <td>0.497614</td>\n","      <td>0.859375</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.208400</td>\n","      <td>0.533606</td>\n","      <td>0.889844</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.110500</td>\n","      <td>0.577234</td>\n","      <td>0.894531</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:18, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.973900</td>\n","      <td>0.649811</td>\n","      <td>0.755469</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.581200</td>\n","      <td>0.575523</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.345000</td>\n","      <td>0.499072</td>\n","      <td>0.871094</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.198200</td>\n","      <td>0.547131</td>\n","      <td>0.882031</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.104200</td>\n","      <td>0.602524</td>\n","      <td>0.887500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.885625\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.90      0.95      0.92       400\n","feature request       0.89      0.89      0.89       400\n","         rating       0.93      0.83      0.88       400\n","user experience       0.82      0.88      0.85       400\n","\n","       accuracy                           0.89      1600\n","      macro avg       0.89      0.89      0.89      1600\n","   weighted avg       0.89      0.89      0.89      1600\n","\n"]}],"source":["print(f\"Now doing: {files_multi[1][0].split('.')[0]}\")\n","main_model(files_multi[1][0].split('.')[0], files_multi[1][0].split('.')[1], 1)\n","print(f\"Now doing: {files_multi[2][0].split('.')[0]}\")\n","main_model(files_multi[2][0].split('.')[0], files_multi[2][0].split('.')[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2583942,"status":"ok","timestamp":1709506798699,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"UrOR_Q-eJY1L","outputId":"d4eb5609-4edb-4b15-d5f1-ebf255710462"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_balanced_4000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.303200</td>\n","      <td>0.970847</td>\n","      <td>0.581250</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.509400</td>\n","      <td>0.336554</td>\n","      <td>0.918750</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.247900</td>\n","      <td>0.246451</td>\n","      <td>0.950000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.179300</td>\n","      <td>0.234713</td>\n","      <td>0.948438</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.111300</td>\n","      <td>0.257092</td>\n","      <td>0.953125</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.283200</td>\n","      <td>0.737175</td>\n","      <td>0.709375</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.451000</td>\n","      <td>0.386376</td>\n","      <td>0.925000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.250500</td>\n","      <td>0.262058</td>\n","      <td>0.942187</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.185700</td>\n","      <td>0.243446</td>\n","      <td>0.948438</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.132600</td>\n","      <td>0.305518</td>\n","      <td>0.945312</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.270500</td>\n","      <td>0.747478</td>\n","      <td>0.715625</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.500900</td>\n","      <td>0.316767</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.269500</td>\n","      <td>0.261628</td>\n","      <td>0.951562</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.175100</td>\n","      <td>0.292895</td>\n","      <td>0.939063</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.116800</td>\n","      <td>0.296408</td>\n","      <td>0.946875</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.280900</td>\n","      <td>0.791082</td>\n","      <td>0.689063</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.462200</td>\n","      <td>0.646590</td>\n","      <td>0.806250</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.232500</td>\n","      <td>0.205817</td>\n","      <td>0.960938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.178800</td>\n","      <td>0.234453</td>\n","      <td>0.946875</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.121400</td>\n","      <td>0.239507</td>\n","      <td>0.953125</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.273500</td>\n","      <td>0.797301</td>\n","      <td>0.680751</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.469000</td>\n","      <td>0.263166</td>\n","      <td>0.943662</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.260200</td>\n","      <td>0.273912</td>\n","      <td>0.946792</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.189600</td>\n","      <td>0.223367</td>\n","      <td>0.951487</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.117600</td>\n","      <td>0.307387</td>\n","      <td>0.931142</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.9675\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.99      0.96      0.98       200\n","feature request       0.99      0.98      0.98       200\n","         rating       0.96      0.94      0.95       200\n","user experience       0.92      0.98      0.95       200\n","\n","       accuracy                           0.97       800\n","      macro avg       0.97      0.97      0.97       800\n","   weighted avg       0.97      0.97      0.97       800\n","\n","Now doing: dataset_gpt_balanced_8000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:21, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.835800</td>\n","      <td>0.226062</td>\n","      <td>0.958594</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.196700</td>\n","      <td>0.129002</td>\n","      <td>0.977344</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.138100</td>\n","      <td>0.165315</td>\n","      <td>0.971094</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.086400</td>\n","      <td>0.173331</td>\n","      <td>0.971094</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.051200</td>\n","      <td>0.161498</td>\n","      <td>0.976562</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:18, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.879700</td>\n","      <td>0.246212</td>\n","      <td>0.950000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.175800</td>\n","      <td>0.146250</td>\n","      <td>0.975781</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.110300</td>\n","      <td>0.116032</td>\n","      <td>0.975781</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.070900</td>\n","      <td>0.113473</td>\n","      <td>0.978125</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.042600</td>\n","      <td>0.127842</td>\n","      <td>0.977344</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.899900</td>\n","      <td>0.276715</td>\n","      <td>0.941406</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.194000</td>\n","      <td>0.178792</td>\n","      <td>0.971875</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.119700</td>\n","      <td>0.172439</td>\n","      <td>0.972656</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.086700</td>\n","      <td>0.197932</td>\n","      <td>0.970313</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.052400</td>\n","      <td>0.198142</td>\n","      <td>0.969531</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:16, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.894300</td>\n","      <td>0.237667</td>\n","      <td>0.945312</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.166200</td>\n","      <td>0.183934</td>\n","      <td>0.964063</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.123400</td>\n","      <td>0.199040</td>\n","      <td>0.967187</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.083000</td>\n","      <td>0.219575</td>\n","      <td>0.964063</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.048800</td>\n","      <td>0.232005</td>\n","      <td>0.964063</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:19, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.858800</td>\n","      <td>0.222347</td>\n","      <td>0.953088</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.179800</td>\n","      <td>0.181873</td>\n","      <td>0.965598</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.132900</td>\n","      <td>0.147743</td>\n","      <td>0.973417</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.092100</td>\n","      <td>0.147136</td>\n","      <td>0.978108</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.061300</td>\n","      <td>0.159350</td>\n","      <td>0.974980</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.98375\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.99      0.97      0.98       400\n","feature request       1.00      0.98      0.99       400\n","         rating       0.98      0.99      0.98       400\n","user experience       0.97      1.00      0.98       400\n","\n","       accuracy                           0.98      1600\n","      macro avg       0.98      0.98      0.98      1600\n","   weighted avg       0.98      0.98      0.98      1600\n","\n"]}],"source":["print(f\"Now doing: {files_multi[3][0].split('.')[0]}\")\n","main_model(files_multi[3][0].split('.')[0], files_multi[3][0].split('.')[1], 1)\n","print(f\"Now doing: {files_multi[4][0].split('.')[0]}\")\n","main_model(files_multi[4][0].split('.')[0], files_multi[4][0].split('.')[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3270621,"status":"ok","timestamp":1709512664838,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"Tw3GyogaU4mI","outputId":"fc638a26-85e2-48f4-95f3-d2f0bac1a841"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_balanced_20000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6270' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6270/7115 11:13 < 01:30, 9.31 it/s, Epoch 4.41/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.389700</td>\n","      <td>0.099815</td>\n","      <td>0.979688</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.090100</td>\n","      <td>0.079041</td>\n","      <td>0.985000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.056300</td>\n","      <td>0.058820</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.035500</td>\n","      <td>0.080140</td>\n","      <td>0.989375</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 12:49, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.389700</td>\n","      <td>0.099815</td>\n","      <td>0.979688</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.090100</td>\n","      <td>0.079041</td>\n","      <td>0.985000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.056300</td>\n","      <td>0.058820</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.035500</td>\n","      <td>0.080140</td>\n","      <td>0.989375</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.021300</td>\n","      <td>0.086336</td>\n","      <td>0.989062</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 12:35, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.405900</td>\n","      <td>0.086388</td>\n","      <td>0.987187</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.081200</td>\n","      <td>0.073526</td>\n","      <td>0.987812</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.060200</td>\n","      <td>0.074098</td>\n","      <td>0.988125</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.037300</td>\n","      <td>0.060269</td>\n","      <td>0.990625</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.019900</td>\n","      <td>0.061281</td>\n","      <td>0.990625</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_20000/Dump/res/checkpoint-7115 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 12:35, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.389300</td>\n","      <td>0.099227</td>\n","      <td>0.983750</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.075200</td>\n","      <td>0.105518</td>\n","      <td>0.984688</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.056100</td>\n","      <td>0.139558</td>\n","      <td>0.974688</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.036000</td>\n","      <td>0.078742</td>\n","      <td>0.987812</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.019300</td>\n","      <td>0.092609</td>\n","      <td>0.987187</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_20000/Dump/res/checkpoint-7115 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 12:35, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.405400</td>\n","      <td>0.086590</td>\n","      <td>0.985000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.072300</td>\n","      <td>0.058463</td>\n","      <td>0.990313</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.060300</td>\n","      <td>0.067770</td>\n","      <td>0.990000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.031200</td>\n","      <td>0.070834</td>\n","      <td>0.989688</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.013700</td>\n","      <td>0.077259</td>\n","      <td>0.990000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_20000/Dump/res/checkpoint-7115 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7115' max='7115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7115/7115 12:34, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.398700</td>\n","      <td>0.119435</td>\n","      <td>0.979994</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.076800</td>\n","      <td>0.084506</td>\n","      <td>0.987809</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.051500</td>\n","      <td>0.079264</td>\n","      <td>0.987496</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.029800</td>\n","      <td>0.080686</td>\n","      <td>0.987496</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.017100</td>\n","      <td>0.077842</td>\n","      <td>0.987183</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_20000/Dump/res/checkpoint-7115 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.993\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.99      0.99      0.99      1000\n","feature request       1.00      0.99      1.00      1000\n","         rating       0.99      0.99      0.99      1000\n","user experience       0.99      0.99      0.99      1000\n","\n","       accuracy                           0.99      4000\n","      macro avg       0.99      0.99      0.99      4000\n","   weighted avg       0.99      0.99      0.99      4000\n","\n"]}],"source":["print(f\"Now doing: {files_multi[5][0].split('.')[0]}\")\n","main_model(files_multi[5][0].split('.')[0], files_multi[5][0].split('.')[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6317120,"status":"ok","timestamp":1709519187919,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"77ABfWWy6iou","outputId":"7aaa128b-aa28-494f-c426-18bbca823125"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_balanced_32000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11380' max='11380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11380/11380 19:59, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.254900</td>\n","      <td>0.069666</td>\n","      <td>0.989648</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.050200</td>\n","      <td>0.050320</td>\n","      <td>0.991797</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.037500</td>\n","      <td>0.049635</td>\n","      <td>0.992383</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.026000</td>\n","      <td>0.044190</td>\n","      <td>0.993164</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.012700</td>\n","      <td>0.053193</td>\n","      <td>0.993359</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11380' max='11380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11380/11380 19:56, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.264000</td>\n","      <td>0.060840</td>\n","      <td>0.989453</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.051200</td>\n","      <td>0.031485</td>\n","      <td>0.994727</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.037600</td>\n","      <td>0.027175</td>\n","      <td>0.994727</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.023600</td>\n","      <td>0.029871</td>\n","      <td>0.994531</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.012900</td>\n","      <td>0.039747</td>\n","      <td>0.994922</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_32000/Dump/res/checkpoint-11380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11380' max='11380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11380/11380 20:03, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.262400</td>\n","      <td>0.094733</td>\n","      <td>0.983984</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.051300</td>\n","      <td>0.047519</td>\n","      <td>0.992773</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.035600</td>\n","      <td>0.039649</td>\n","      <td>0.994141</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.024500</td>\n","      <td>0.044042</td>\n","      <td>0.993555</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.011900</td>\n","      <td>0.051682</td>\n","      <td>0.993359</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_32000/Dump/res/checkpoint-11380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11380' max='11380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11380/11380 20:25, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.263200</td>\n","      <td>0.068768</td>\n","      <td>0.987891</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.051100</td>\n","      <td>0.047052</td>\n","      <td>0.990430</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.034700</td>\n","      <td>0.051512</td>\n","      <td>0.991602</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.024600</td>\n","      <td>0.046213</td>\n","      <td>0.994141</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.012100</td>\n","      <td>0.056590</td>\n","      <td>0.993359</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_32000/Dump/res/checkpoint-11380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11380' max='11380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11380/11380 20:28, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.274500</td>\n","      <td>0.070148</td>\n","      <td>0.989842</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.053600</td>\n","      <td>0.053374</td>\n","      <td>0.992381</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.034200</td>\n","      <td>0.048243</td>\n","      <td>0.993553</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.022700</td>\n","      <td>0.042476</td>\n","      <td>0.992772</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.009900</td>\n","      <td>0.046125</td>\n","      <td>0.993163</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Balanced/dataset_gpt_balanced_32000/Dump/res/checkpoint-11380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.994375\n","                 precision    recall  f1-score   support\n","\n","     bug report       1.00      1.00      1.00      1600\n","feature request       1.00      1.00      1.00      1600\n","         rating       0.99      0.99      0.99      1600\n","user experience       0.99      0.99      0.99      1600\n","\n","       accuracy                           0.99      6400\n","      macro avg       0.99      0.99      0.99      6400\n","   weighted avg       0.99      0.99      0.99      6400\n","\n"]}],"source":["print(f\"Now doing: {files_multi[6][0].split('.')[0]}\")\n","main_model(files_multi[6][0].split('.')[0], files_multi[6][0].split('.')[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLvtXSZUfZZq"},"outputs":[],"source":["directory_path_unbalanced = path_to_project / 'Data' / 'Datasets' / 'Unbalanced'\n","\n","files_unbalanced = [(file.name, file.stat().st_size)\n","               for file in directory_path_unbalanced.iterdir()\n","               if file.is_file() and not file.name.startswith('.')]\n","\n","files_unbalanced.sort(key=lambda x: x[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e49de008fb6d4bdc92a6e9c329d59ff0","0de29eb276804915acbaf426b0e5fa3f","767b0bb35cce4a55a93f6b2459e4666b","b7ae5bfb76454a23897baa48f941f72d","587f763a523e44f3b38a25111694b9dc","7eb08ebc0d8a44ddbf1e617aca90d6df","623273a25db94d98830014e5abd7aea3","71f7866e0be94664a2115478041799bc","0f444c0b446e4555809ba97ae3f7873a","37fc7d2ec0a74bebb96f9db1c0b21ee0","21abafe318344343ae9c2dae4ac9229c","94338236b8dd4fc3bd04fe04ff27e2ad","b2d4bc4629e344b3bbcbaa70f1f46fa3","0d71d99ab2154b7fb8ab08738f2c71d2","dc31769949904f51aa100ee3a40e0c67","ffe8124e1bef4c29a3404077f87307ba","0dfecee3c93249218bed9c7995916acf","99059350bb5d4276be6e9466401bf0f0","866b8e75fe7a491a8f36406c1896f8bd","cd43da46a47e48fba2f51b3a1599ffd6","05d88a634bdb456aa9e06d7a42b70627","ef7b03d126564b66a0644bfd937aeac3","a805b6e6c60941f699672f9f2827c159","91aae9dd78d5407aa13a29a272f98810","2a96de1958a94386b38ff85552045a9c","35db0ffe4c974f63bd6b38edb6636c03","207fdd678a8d4c56b75b4ba9a6aa0da1","b3de702f9af648c69e5c7c04d8d637e0","ae9b3ce2408a48a38ae96835ade0a3fb","bdc68768388f4d2baa096eb78a27f027","4136e7f3caab45519129891cbc3ec2c4","2816e196a7664c99ab3d6670c5eaa50d","774de44ea7d749b48409beb8ddbc44e9","f3ac39008ee74598a9b9826329ebde98","a56c904aa53347d496af04862be1748f","4f880704aecb4ebbbaf696c97afed1cb","08aa6a7467cf43db86b52c84af725447","442d4495dfcf422dbd92873f1d4bf6d5","84d1c053d7e44120ab6ae7919310298c","479d73bbb8614ae596ad95d7114e8fd5","4579414e56ea418d92144c8a8fa043ce","f4ec49665e3445ccb04f89139f07a234","41885922f89a43709b98cfac38cea421","74cf6dd0943c496a81674f82b3607e1b","a41d8d368b1a4ff9bfbad465cc308f88","e6248a34418342419a76a7890a8f74d6","528a949ce640410daff9d18934d91775","68eef1114f8e4946b5b917f7fa040d37","1b1525f161c24137b8bc19ec88abc821","21d1d695d85a498193e807685b3d659c","bbc292ecfb4941a7869177f774b43a1a","73111060649547aa99e8d2654d7fa52c","1604639d52c84c83b473021edf8529f7","ff4714100f0f40f59587ef35aba8f451","e0d14f134cd9483885cf1582bd54cff1"]},"executionInfo":{"elapsed":1830394,"status":"ok","timestamp":1709564401016,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"Xrv_K0twu68I","outputId":"8dba58c0-7ec9-438c-90fd-6d756f8147a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_unbalanced_4000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e49de008fb6d4bdc92a6e9c329d59ff0","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94338236b8dd4fc3bd04fe04ff27e2ad","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a805b6e6c60941f699672f9f2827c159","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3ac39008ee74598a9b9826329ebde98","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold 1/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a41d8d368b1a4ff9bfbad465cc308f88","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.095200</td>\n","      <td>0.719020</td>\n","      <td>0.734375</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.679300</td>\n","      <td>0.599432</td>\n","      <td>0.801562</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.451400</td>\n","      <td>0.515790</td>\n","      <td>0.835938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.266400</td>\n","      <td>0.594305</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.141900</td>\n","      <td>0.637849</td>\n","      <td>0.860938</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.092200</td>\n","      <td>0.667296</td>\n","      <td>0.737500</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.641700</td>\n","      <td>0.670883</td>\n","      <td>0.767188</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.417200</td>\n","      <td>0.643683</td>\n","      <td>0.787500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.250300</td>\n","      <td>0.808369</td>\n","      <td>0.821875</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.114900</td>\n","      <td>0.885504</td>\n","      <td>0.829688</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.079100</td>\n","      <td>0.728757</td>\n","      <td>0.715625</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.682600</td>\n","      <td>0.540833</td>\n","      <td>0.785937</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.423800</td>\n","      <td>0.581161</td>\n","      <td>0.835938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.259700</td>\n","      <td>0.628660</td>\n","      <td>0.842187</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.125800</td>\n","      <td>0.705461</td>\n","      <td>0.857812</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.092700</td>\n","      <td>0.690871</td>\n","      <td>0.754687</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.645800</td>\n","      <td>0.523728</td>\n","      <td>0.807813</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.427400</td>\n","      <td>0.574516</td>\n","      <td>0.832812</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.240600</td>\n","      <td>0.664932</td>\n","      <td>0.867188</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.105500</td>\n","      <td>0.719454</td>\n","      <td>0.853125</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.078100</td>\n","      <td>0.677464</td>\n","      <td>0.740625</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.663800</td>\n","      <td>0.633365</td>\n","      <td>0.768750</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.435200</td>\n","      <td>0.620418</td>\n","      <td>0.785937</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.229500</td>\n","      <td>0.831357</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.129500</td>\n","      <td>0.887396</td>\n","      <td>0.812500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.82375\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.83      0.89      0.86       251\n","feature request       0.86      0.84      0.85       282\n","         rating       0.90      0.68      0.78       148\n","user experience       0.68      0.81      0.74       119\n","\n","       accuracy                           0.82       800\n","      macro avg       0.82      0.81      0.81       800\n","   weighted avg       0.83      0.82      0.82       800\n","\n","Now doing: dataset_gpt_unbalanced_4000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.185000</td>\n","      <td>0.606562</td>\n","      <td>0.806250</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.355000</td>\n","      <td>0.110625</td>\n","      <td>0.981250</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.107900</td>\n","      <td>0.064429</td>\n","      <td>0.984375</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.052400</td>\n","      <td>0.048608</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.026300</td>\n","      <td>0.044213</td>\n","      <td>0.987500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.153900</td>\n","      <td>1.024560</td>\n","      <td>0.634375</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.318200</td>\n","      <td>0.159639</td>\n","      <td>0.971875</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.114400</td>\n","      <td>0.093093</td>\n","      <td>0.985938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.058300</td>\n","      <td>0.125630</td>\n","      <td>0.978125</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.033200</td>\n","      <td>0.102540</td>\n","      <td>0.982812</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.163700</td>\n","      <td>0.911059</td>\n","      <td>0.656250</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.338900</td>\n","      <td>0.261155</td>\n","      <td>0.945312</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.104000</td>\n","      <td>0.097756</td>\n","      <td>0.985938</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.053400</td>\n","      <td>0.121374</td>\n","      <td>0.982812</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.028700</td>\n","      <td>0.121680</td>\n","      <td>0.982812</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:54, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.150100</td>\n","      <td>1.119831</td>\n","      <td>0.545312</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.397500</td>\n","      <td>0.147767</td>\n","      <td>0.964063</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.116700</td>\n","      <td>0.121739</td>\n","      <td>0.981250</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.058000</td>\n","      <td>0.154185</td>\n","      <td>0.978125</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.030800</td>\n","      <td>0.152002</td>\n","      <td>0.979688</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.176200</td>\n","      <td>0.730435</td>\n","      <td>0.739062</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.338100</td>\n","      <td>0.222268</td>\n","      <td>0.964063</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.103200</td>\n","      <td>0.123400</td>\n","      <td>0.981250</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.046300</td>\n","      <td>0.143124</td>\n","      <td>0.979688</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.016700</td>\n","      <td>0.148467</td>\n","      <td>0.979688</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.985\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.99      0.98      0.98       100\n","feature request       0.99      0.97      0.98       150\n","         rating       1.00      0.98      0.99       250\n","user experience       0.97      0.99      0.98       300\n","\n","       accuracy                           0.98       800\n","      macro avg       0.99      0.98      0.99       800\n","   weighted avg       0.99      0.98      0.99       800\n","\n"]}],"source":["print(f\"Now doing: {files_unbalanced[0][0].split('.')[0]}\")\n","main_model(files_unbalanced[0][0].split('.')[0], files_unbalanced[0][0].split('.')[1], 2)\n","print(f\"Now doing: {files_unbalanced[1][0].split('.')[0]}\")\n","main_model(files_unbalanced[1][0].split('.')[0], files_unbalanced[1][0].split('.')[1], 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":200943,"status":"ok","timestamp":1709567587442,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"lz1e87NU0Qdh","outputId":"d796fbd3-8c3e-4821-b9fa-a7a17d8ed05d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_unbalanced_8000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:16, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.740800</td>\n","      <td>0.206736</td>\n","      <td>0.958594</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.117200</td>\n","      <td>0.071571</td>\n","      <td>0.987500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.055800</td>\n","      <td>0.081072</td>\n","      <td>0.986719</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.034100</td>\n","      <td>0.076401</td>\n","      <td>0.989844</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.022500</td>\n","      <td>0.105100</td>\n","      <td>0.983594</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:18, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.833300</td>\n","      <td>0.246019</td>\n","      <td>0.950000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.113900</td>\n","      <td>0.091965</td>\n","      <td>0.985938</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.043900</td>\n","      <td>0.082670</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.030200</td>\n","      <td>0.087097</td>\n","      <td>0.986719</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.018700</td>\n","      <td>0.084065</td>\n","      <td>0.988281</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.801900</td>\n","      <td>0.148907</td>\n","      <td>0.967187</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.107600</td>\n","      <td>0.091225</td>\n","      <td>0.987500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.052800</td>\n","      <td>0.088977</td>\n","      <td>0.987500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.033000</td>\n","      <td>0.074318</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.023300</td>\n","      <td>0.085450</td>\n","      <td>0.987500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.752100</td>\n","      <td>0.207078</td>\n","      <td>0.967187</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.109600</td>\n","      <td>0.076639</td>\n","      <td>0.989844</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.055400</td>\n","      <td>0.071589</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.021700</td>\n","      <td>0.081597</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.013400</td>\n","      <td>0.075698</td>\n","      <td>0.989844</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1211' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1211/2845 02:14 < 03:01, 8.99 it/s, Epoch 2.13/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.814500</td>\n","      <td>0.134374</td>\n","      <td>0.968726</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.101700</td>\n","      <td>0.065714</td>\n","      <td>0.989836</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.814500</td>\n","      <td>0.134374</td>\n","      <td>0.968726</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.101700</td>\n","      <td>0.065714</td>\n","      <td>0.989836</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.053500</td>\n","      <td>0.057245</td>\n","      <td>0.992181</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.024500</td>\n","      <td>0.054962</td>\n","      <td>0.992181</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.015900</td>\n","      <td>0.057987</td>\n","      <td>0.992181</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.994375\n","                 precision    recall  f1-score   support\n","\n","     bug report       1.00      0.99      0.99       200\n","feature request       1.00      1.00      1.00       300\n","         rating       1.00      0.99      0.99       500\n","user experience       0.99      1.00      0.99       600\n","\n","       accuracy                           0.99      1600\n","      macro avg       1.00      0.99      0.99      1600\n","   weighted avg       0.99      0.99      0.99      1600\n","\n"]}],"source":["print(f\"Now doing: {files_unbalanced[2][0].split('.')[0]}\")\n","main_model(files_unbalanced[2][0].split('.')[0], files_unbalanced[2][0].split('.')[1], 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ab61a05477124cc095c926afb85c2ebd","596f5836ffae491faa020e9e144fa385","c83137d0e09f488f89956a8d6d465c0b","13a7be63dce943bea53f3ecddca26b5e","1ed3ac9c8e70457e9e1f6b2de53b9b4c","ad19e8e20d2842af86d1fbcf0dbc4cd7","98992f22604b4238af8a6bf99fa644d1","692c194bca1f4ba4b394f4e2b71f8f7a","2257e510e82847ee84c7e96d4cfa531b","633e140611e44e07bc0a9146813e5420","b8bdda7a3b2b4d3f897dcf56097b39c6","95bdeac851904c1b92af09bc625ef62a","0707517a0ca74fb09b8fbec03f3404b4","70547ca26b6544f7a9e59116c4af1416","74d15072448f47eeb0790fd39c797ce2","7e28f0f4b7404929a37fc25ca251e40f","d815cbbb62c74dfcb0ad786e16471e49","0f52c2459c5d4d45b6fd694a1ee6d3cf","4e795fd86660407e84cb0251446f3a2e","d26ae8a6ba0d405ca4113339440cb564","a8254fc31b034d0a879d3a9aca628084","f4c11eee9c064a229c4292861a7cce8a","cd682addc8544596aef1c53f1887c5f5","f0e8e94b3d254794a8f697922e256a73","2d23fa49ee9d4841a43794d79d129256","459e3aa0608e405cb9eaafecb2a671f3","b1c0ec4a95d94eb4baf41ccfe6c1e0e5","d6b6d2978f4c413481ba47c2a4ec2bb0","c24ed5712a254bedb185b1a47159f056","2a5182a4dcfb45f0a51dad40392ccb60","7d518cf8ac2e494e9a0b877a8ab25953","165e2cb18baa4ebba0e0c6b77f11d135","a3f5df8538cd488da8a36ae4d6b783e1","dd5b225e19034e28b311d73360c0163d","85788fd36887493e8a6796b17afb2dd6","bc390ead714e4413b134e7d3b6d46e25","4f49e20038664cb78c4ef0865aae880d","15a881438f904d54824ad47ecec06c1e","2cc220d33f4a481298c67a3746fecf0a","c9ce96a96dbc4662ab90f07f6e9a86ee","6ce4a8c2e5424624ad6770c8ae9404dd","f98326afd2734c0c9d2cdc4c1aaddb03","07e574af52bd446cbd1da4e2613cbfdc","65cc9f04470a46bb80363a62071a9e27","200007a05e33493bbf75c849db809709","896827fe1a1d4e9abfc0344ac502ba05","a351e9b58d644cb4ad35159b64d2be11","dac0a49c448248458c80b5dfc446d3d1","466c8de504474f9f9197aea9bc698fa9","83224023d36945f8b8ee0e12411f058b","06fa750077c544c5bc3a3d33c3dd2563","2bd6788c5e0541e48b8fbaf2fa2846cb","274bfda4e20b4a62966af1ec40804224","6733a3ceae704c88a35039236f466841","770f97909cce468c92aa5fc0e9941dbc"]},"executionInfo":{"elapsed":3186409,"status":"ok","timestamp":1709590122956,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"agR6_OmS3Pn2","outputId":"ce7fc447-5c01-4528-8fee-10cc83fa92bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_unbalanced_16000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab61a05477124cc095c926afb85c2ebd","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95bdeac851904c1b92af09bc625ef62a","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd682addc8544596aef1c53f1887c5f5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd5b225e19034e28b311d73360c0163d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold 1/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"200007a05e33493bbf75c849db809709","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:04, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.419000</td>\n","      <td>0.073987</td>\n","      <td>0.987891</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.062600</td>\n","      <td>0.072323</td>\n","      <td>0.988281</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.033400</td>\n","      <td>0.094485</td>\n","      <td>0.987891</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.021100</td>\n","      <td>0.066701</td>\n","      <td>0.991016</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.010400</td>\n","      <td>0.076022</td>\n","      <td>0.991016</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:10, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.420900</td>\n","      <td>0.080783</td>\n","      <td>0.987109</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.059200</td>\n","      <td>0.079417</td>\n","      <td>0.986328</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.042500</td>\n","      <td>0.053605</td>\n","      <td>0.992969</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.025100</td>\n","      <td>0.053311</td>\n","      <td>0.992969</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.013100</td>\n","      <td>0.051711</td>\n","      <td>0.992188</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:07, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.429100</td>\n","      <td>0.071305</td>\n","      <td>0.989844</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.071100</td>\n","      <td>0.037259</td>\n","      <td>0.993359</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.041800</td>\n","      <td>0.061048</td>\n","      <td>0.991016</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.024000</td>\n","      <td>0.057970</td>\n","      <td>0.992578</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.014300</td>\n","      <td>0.065118</td>\n","      <td>0.992578</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:08, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.408600</td>\n","      <td>0.134663</td>\n","      <td>0.978906</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.058600</td>\n","      <td>0.041802</td>\n","      <td>0.992578</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.041000</td>\n","      <td>0.049536</td>\n","      <td>0.993359</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.028000</td>\n","      <td>0.050651</td>\n","      <td>0.992969</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.011300</td>\n","      <td>0.060449</td>\n","      <td>0.991797</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:17, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.421900</td>\n","      <td>0.057937</td>\n","      <td>0.988277</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.062800</td>\n","      <td>0.045237</td>\n","      <td>0.992575</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.038600</td>\n","      <td>0.040430</td>\n","      <td>0.994138</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.029300</td>\n","      <td>0.047631</td>\n","      <td>0.993748</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.017100</td>\n","      <td>0.047808</td>\n","      <td>0.993748</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Unbalanced/dataset_gpt_unbalanced_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:143: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-3-7e7d6f984ec5>:180: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  full_metrics_df = full_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.995625\n","                 precision    recall  f1-score   support\n","\n","     bug report       0.99      0.99      0.99       400\n","feature request       1.00      1.00      1.00       600\n","         rating       1.00      0.99      1.00      1000\n","user experience       0.99      1.00      1.00      1200\n","\n","       accuracy                           1.00      3200\n","      macro avg       1.00      0.99      1.00      3200\n","   weighted avg       1.00      1.00      1.00      3200\n","\n"]}],"source":["print(f\"Now doing: {files_unbalanced[3][0].split('.')[0]}\")\n","main_model(files_unbalanced[3][0].split('.')[0], files_unbalanced[3][0].split('.')[1], 2)"]},{"cell_type":"markdown","metadata":{},"source":["## Multi-label classification using BART"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1287,"status":"ok","timestamp":1709594713637,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"WonoRSL1Kb9w"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, KFold\n","from transformers import BartTokenizer, BartForSequenceClassification, TrainingArguments, Trainer\n","import torch\n","from torch.utils.data import Dataset\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n","from transformers import TrainerCallback\n","import os\n","import shutil\n","import re\n","import time\n","from pathlib import Path\n","import numpy as np\n","\n","def multi_main_model(file_name, ext):\n","\n","    current_file_path = Path(__file__).parent\n","\n","    path_to_project = current_file_path.parents[1]\n","\n","    df = pd.read_csv(f\"{path_to_project}/Data/Datasets/Multi-label/{file_name}.{ext}\")\n","\n","    results_dir = f\"{path_to_project}/Models/BART/Output/Multi-label/{file_name}\"\n","    dump_dir = results_dir+\"/Dump\"\n","\n","    if os.path.isdir(results_dir):\n","        shutil.rmtree(results_dir)\n","\n","    os.mkdir(results_dir)\n","    os.mkdir(dump_dir)\n","\n","    df = df[df['review'].notna() & (df['review'] != '')]\n","    df['review'] = df['review'].str.replace('[^\\x20-\\x7E]', '', regex=True)\n","\n","    X = df['review'].values\n","    y = df[['bug report', 'user experience', 'rating', 'feature request']].values\n","\n","    X_train_CV, X_test_full, y_train_CV, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","    def tokenize_function(examples):\n","        return tokenizer(examples, padding=\"max_length\", truncation=True, max_length=128)\n","\n","    loss_logging_callback = LossLoggingCallback()\n","\n","    # K-Fold Cross-Validation\n","    n_splits = 5\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    # Variables to accumulate scores\n","    best_f1 = 0\n","    best_model = None\n","    metrics_df = pd.DataFrame()\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(X_train_CV, y_train_CV)):\n","        print(f\"Fold {fold+1}/{n_splits}\")\n","        start_time = time.time()\n","\n","        X_train, X_val = X_train_CV[train_index], X_train_CV[val_index]\n","        y_train, y_val = y_train_CV[train_index], y_train_CV[val_index]\n","\n","        train_encodings = tokenize_function(X_train.tolist())\n","        val_encodings = tokenize_function(X_val.tolist())\n","\n","        train_dataset = MultiLabelDataset(train_encodings, y_train)\n","        val_dataset = MultiLabelDataset(val_encodings, y_val)\n","\n","        model = BartForSequenceClassification.from_pretrained('facebook/bart-base', num_labels=4, problem_type=\"multi_label_classification\")\n","\n","        training_args = TrainingArguments(\n","            output_dir=f\"{dump_dir}/res\",\n","            num_train_epochs=5,\n","            per_device_train_batch_size=9,\n","            per_device_eval_batch_size=21,\n","            warmup_steps=500,\n","            weight_decay=0.11210091359531205,\n","            logging_dir=f\"{dump_dir}/logs\",\n","            logging_strategy=\"epoch\",\n","            evaluation_strategy=\"epoch\",\n","            learning_rate=3.328079168300429e-05,\n","            max_grad_norm=1.0,\n","            load_best_model_at_end=True,\n","            metric_for_best_model=\"f1\",\n","            save_strategy=\"epoch\",\n","            save_total_limit=2,\n","            lr_scheduler_type='linear'\n","        )\n","\n","        def compute_metrics(trainer_prediction):\n","            logits = trainer_prediction.predictions\n","            labels = trainer_prediction.label_ids\n","            # Check if the logits are wrapped in a tuple (this is usually not the case with predict(), but included for completeness)\n","            if isinstance(logits, tuple):\n","                logits = logits[0]\n","            # Compute the predicted class indices\n","            predictions = torch.sigmoid(torch.tensor(logits)).numpy()\n","            threshold = 0.5\n","            predictions = (predictions > threshold).astype(int)\n","            precision = precision_score(labels, predictions, average='micro')\n","            recall = recall_score(labels, predictions, average='micro')\n","            f1 = f1_score(labels, predictions, average='micro')\n","            return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","        def get_pred(trainer_prediction):\n","            logits = trainer_prediction.predictions\n","            labels = trainer_prediction.label_ids\n","            # Check if the logits are wrapped in a tuple (this is usually not the case with predict(), but included for completeness)\n","            if isinstance(logits, tuple):\n","                logits = logits[0]\n","            # Compute the predicted class indices\n","            predictions = torch.sigmoid(torch.tensor(logits)).numpy()\n","            return predictions\n","\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=val_dataset,\n","            compute_metrics=compute_metrics,\n","            callbacks=[loss_logging_callback]\n","        )\n","\n","        trainer.train()\n","\n","        loss_logging_callback.save_logs_to_excel(f\"{results_dir}/fold_loss.xlsx\")\n","\n","        results = trainer.evaluate()\n","\n","        if results['eval_f1'] > best_f1:\n","            best_f1 = results['eval_f1']\n","            best_model = model\n","\n","\n","        predictions = trainer.predict(val_dataset)\n","        pred_probs = get_pred(predictions)\n","        threshold = 0.5\n","        binary_predictions = (pred_probs > threshold).astype(int)\n","\n","        # True labels\n","        true_labels = predictions.label_ids\n","        f1 = f1_score(true_labels, binary_predictions, average='micro')\n","\n","        report_dict = classification_report(true_labels, binary_predictions, output_dict=True, zero_division=0, target_names=['bug report', 'user experience', 'rating', 'feature request'])\n","        # avg_metrics = report_dict['weighted avg']  # Use 'macro avg' or 'weighted avg' based on your preference\n","        end_time = time.time()\n","        # Append the metrics for this fold to the DataFrame\n","        metrics_df = metrics_df.append({\n","            ('Fold', ''): fold + 1,\n","            ('F1-Score', ''): f1,\n","            ('Train Time', ''): str(end_time - start_time)+\" s\",\n","            ('Bug Report', 'P'): report_dict['bug report']['precision'],\n","            ('Bug Report', 'R'): report_dict['bug report']['recall'],\n","            ('Bug Report', 'F1'): report_dict['bug report']['f1-score'],\n","            ('Feature Request', 'P'): report_dict['feature request']['precision'],\n","            ('Feature Request', 'R'): report_dict['feature request']['recall'],\n","            ('Feature Request', 'F1'): report_dict['feature request']['f1-score'],\n","            ('Rating', 'P'): report_dict['rating']['precision'],\n","            ('Rating', 'R'): report_dict['rating']['recall'],\n","            ('Rating', 'F1'): report_dict['rating']['f1-score'],\n","            ('User Experience', 'P'): report_dict['user experience']['precision'],\n","            ('User Experience', 'R'): report_dict['user experience']['recall'],\n","            ('User Experience', 'F1'): report_dict['user experience']['f1-score']\n","        }, ignore_index=True)\n","\n","    metrics_df.columns = pd.MultiIndex.from_tuples([(c,) if isinstance(c, str) else c for c in metrics_df.columns])\n","    metrics_df.to_excel(f\"{results_dir}/fold_metrics.xlsx\", index=True)\n","\n","    test_encodings = tokenize_function(X_test_full.tolist())\n","    test_dataset = MultiLabelDataset(test_encodings, y_test_full)\n","    test_trainer = Trainer(model=best_model)\n","    test_predictions = test_trainer.predict(test_dataset)\n","    test_pred_probs = get_pred(test_predictions)\n","    threshold = 0.5\n","    test_binary_predictions = (test_pred_probs > threshold).astype(int)\n","\n","    test_true_labels = test_predictions.label_ids\n","    test_f1 = f1_score(test_true_labels, test_binary_predictions, average='micro')\n","\n","    test_report_dict = classification_report(test_true_labels, test_binary_predictions, output_dict=True, zero_division=0, target_names=['bug report', 'user experience', 'rating', 'feature request'])\n","    # avg_metrics = report_dict['weighted avg']  # Use 'macro avg' or 'weighted avg' based on your preference\n","    # Append the metrics for this fold to the DataFrame\n","    test_metrics_df = pd.DataFrame()\n","\n","    test_metrics_df = test_metrics_df.append({\n","            ('F1', ''): test_f1,\n","            ('Bug Report', 'P'): test_report_dict['bug report']['precision'],\n","            ('Bug Report', 'R'): test_report_dict['bug report']['recall'],\n","            ('Bug Report', 'F1'): test_report_dict['bug report']['f1-score'],\n","            ('Feature Request', 'P'): test_report_dict['feature request']['precision'],\n","            ('Feature Request', 'R'): test_report_dict['feature request']['recall'],\n","            ('Feature Request', 'F1'): test_report_dict['feature request']['f1-score'],\n","            ('Rating', 'P'): test_report_dict['rating']['precision'],\n","            ('Rating', 'R'): test_report_dict['rating']['recall'],\n","            ('Rating', 'F1'): test_report_dict['rating']['f1-score'],\n","            ('User Experience', 'P'): test_report_dict['user experience']['precision'],\n","            ('User Experience', 'R'): test_report_dict['user experience']['recall'],\n","            ('User Experience', 'F1'): test_report_dict['user experience']['f1-score']\n","        }, ignore_index=True)\n","\n","    test_metrics_df.columns = pd.MultiIndex.from_tuples([(c,) if isinstance(c, str) else c for c in test_metrics_df.columns])\n","    test_metrics_df.to_excel(f\"{results_dir}/metrics_results_full_test.xlsx\", index=True)\n","\n","    print(f\"Test F1: {test_f1}\")\n","\n","    # Generate and print the classification report\n","    print(test_report_dict)\n","\n","    shutil.rmtree(dump_dir)\n","\n","class MultiLabelDataset(Dataset):\n","\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float32)  # Ensure float32 for BCEWithLogitsLoss\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","class LossLoggingCallback(TrainerCallback):\n","    \"\"\"A custom callback to log training and validation loss.\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.log_history = []\n","        self.log_train_loss_history = []\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        # This method captures both training and evaluation logs, so it's more general than on_epoch_end\n","        if logs is not None:\n","            # Capture both training and evaluation steps\n","            if 'loss' in logs:  # Indicates a training step\n","                self.log_train_loss_history.append({\n","                    'epoch': state.epoch,\n","                    'training_loss': logs.get('loss'),\n","                })\n","            elif 'eval_loss' in logs:  # Indicates an evaluation step\n","                # Make sure to capture the last training loss as well\n","                last_training_loss = self.log_train_loss_history[-1]['training_loss'] if self.log_train_loss_history else None\n","                self.log_history.append({\n","                    'epoch': state.epoch,\n","                    'training_loss': last_training_loss,  # Include last known training loss for reference\n","                    'validation_loss': logs.get('eval_loss'),\n","                    'eval_runtime':logs.get('eval_runtime')\n","                })\n","\n","    def save_logs_to_excel(self, file_name):\n","        \"\"\"Save the recorded logs to a Excel file.\"\"\"\n","        pd.DataFrame(self.log_history).to_excel(file_name, index=False)\n","\n","__file__ = \"/content/drive/MyDrive/FinalProject/Models/BART/BART.ipynb\"\n","current_file_path = Path(__file__).parent\n","path_to_project = current_file_path.parents[1]\n","\n","directory_path_multi_label = path_to_project / 'Data' / 'Datasets' / 'Multi-label'\n","\n","files_multi_label = [(file.name, file.stat().st_size)\n","               for file in directory_path_multi_label.iterdir()\n","               if file.is_file() and not file.name.startswith('.')]\n","\n","files_multi_label.sort(key=lambda x: x[1])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6b554276e78b46e1b95d01353b147fc5","f4339f891a3f474c8102a1827b48ab47","97e4adbf14af45f4b89cf7013f4bb0d0","580006a106d14a208d5595fb5303824e","ce0231b9cea841b9ab05b09039ce3661","b70ac8c1d1154c84abc64256126e80b0","5e1a2f616c76479faf675e0d3abacbb5","8fe5175087a2403a80f7273445a19122","80b2e26145d744998c78ce1b8689b582","f4b5d345ee994e848a106bbe78ccfc3b","39d13f90570444418600206e711975f2","2ee62a093c6045ba868c71817b398b0d","0a27ae4897ca4219b0f44f6cf5aac8ec","8bf6d39a2f604cbdba86f720ad4fd89c","b1d1f35c0ae44dc09fe5af0641851cb2","f91b4511e70f4ac498d1cefaa9d1b565","cdc9bfbc9af0450e95e039f01982b22a","1be9dfb5536f4880980c64dc8bca5169","a7d62378b8364c4da5e8479eece0f0d7","9bab5ee18ec1430390ec4554c02e1322","0f764ad634eb4a35ac483aede445975b","6e2d6a77eeb9467b956f5ae65dc22d71","1b06a6e151944455bfea0b89331b95c8","e4a9e96fdf414b018ff81ce55a3f646b","4c294211d3f446108a5ea3599a9ce08a","d3119dfd42a041618d55ff6276bd2ea6","66ed1574eae942fe9a304bbdb34f8865","89be7c09ebce4b7597643fddf5ac2c5f","08c4b3372b2247de822229cddc2175e4","9337bfcba7c1453a973e543e5c9c7bd1","23456a92e6e84583b27615814a0ccdc0","502957b87dda49ec8a0f2067be680cb4","42c8635a5d5d4d1496072b8fcf28acc3","8c67b6e87c8048a1b5549b6bcccbf2dc","b525f9a501584cda8e0a3b4dba75d92e","8e12211a5ebb4de3b26efca80e7eccfa","9331b9c35e514250a9d9b224853af659","9f42e0ab7d224b23b263e3f445d81d9d","5757f7049bcc44b382374bc87f8ab0a4","c53bd76043a348b184e6b7873c9bf365","48dcbef944b54184a6e23361cce6c69b","6930125dc9cf45df9012789bb00342f0","a137e811f00648ccbd73f2854012397f","b2bee341f6ad42c384d2488885ff2c4b","347414beb90e4da891833b53a59077dc","b5f5ab8316fd426789c145f9ee740138","2b8f665439dd497e9675163862e4dba2","3335800dba854fccb6f1ac21b1cf0915","b029dd8d86ee4fad8515292818e1b16c","676a4bd9ad1440868e319bb9abd733f8","4cdadc5afa3449f49b86a65ad9a23638","99547acaf44d4e83b16d2410963586d2","a17f52d2220e4f1597b2c6ce6bbc22ce","50a4352a6214496ab1b54c7ef39d7ba3","f684acff1ee8456c901b3534d8d1d3b9"]},"executionInfo":{"elapsed":980602,"status":"ok","timestamp":1709595722466,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"npZ2N4NkNYHd","outputId":"42063ce6-7a79-4249-8ad4-0612f8fff1fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_multi_label_4000\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b554276e78b46e1b95d01353b147fc5","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ee62a093c6045ba868c71817b398b0d","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b06a6e151944455bfea0b89331b95c8","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c67b6e87c8048a1b5549b6bcccbf2dc","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold 1/5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"347414beb90e4da891833b53a59077dc","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:56, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.625500</td>\n","      <td>0.548425</td>\n","      <td>0.670330</td>\n","      <td>0.804749</td>\n","      <td>0.731415</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.363900</td>\n","      <td>0.244866</td>\n","      <td>0.984227</td>\n","      <td>0.823219</td>\n","      <td>0.896552</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.217200</td>\n","      <td>0.183266</td>\n","      <td>0.983398</td>\n","      <td>0.885664</td>\n","      <td>0.931976</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.143900</td>\n","      <td>0.172309</td>\n","      <td>0.977948</td>\n","      <td>0.897098</td>\n","      <td>0.935780</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.108100</td>\n","      <td>0.179944</td>\n","      <td>0.961003</td>\n","      <td>0.910290</td>\n","      <td>0.934959</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:58, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.616700</td>\n","      <td>0.479571</td>\n","      <td>0.810870</td>\n","      <td>0.643658</td>\n","      <td>0.717653</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.373100</td>\n","      <td>0.235545</td>\n","      <td>0.961765</td>\n","      <td>0.846419</td>\n","      <td>0.900413</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.215600</td>\n","      <td>0.198577</td>\n","      <td>0.968300</td>\n","      <td>0.869715</td>\n","      <td>0.916364</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.174200</td>\n","      <td>0.183885</td>\n","      <td>0.964419</td>\n","      <td>0.888697</td>\n","      <td>0.925011</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.112600</td>\n","      <td>0.156560</td>\n","      <td>0.964960</td>\n","      <td>0.926661</td>\n","      <td>0.945423</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:59, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.617000</td>\n","      <td>0.495122</td>\n","      <td>0.716430</td>\n","      <td>0.785962</td>\n","      <td>0.749587</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.361800</td>\n","      <td>0.225017</td>\n","      <td>0.966732</td>\n","      <td>0.856153</td>\n","      <td>0.908088</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.217800</td>\n","      <td>0.190547</td>\n","      <td>0.985149</td>\n","      <td>0.862218</td>\n","      <td>0.919593</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.160700</td>\n","      <td>0.161203</td>\n","      <td>0.968807</td>\n","      <td>0.915078</td>\n","      <td>0.941176</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.119500</td>\n","      <td>0.158397</td>\n","      <td>0.973247</td>\n","      <td>0.914211</td>\n","      <td>0.942806</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:59, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.612400</td>\n","      <td>0.529975</td>\n","      <td>0.767857</td>\n","      <td>0.651515</td>\n","      <td>0.704918</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.356800</td>\n","      <td>0.244830</td>\n","      <td>0.974460</td>\n","      <td>0.835017</td>\n","      <td>0.899365</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.207400</td>\n","      <td>0.222767</td>\n","      <td>0.921030</td>\n","      <td>0.903199</td>\n","      <td>0.912027</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.143000</td>\n","      <td>0.163294</td>\n","      <td>0.970771</td>\n","      <td>0.922559</td>\n","      <td>0.946051</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.107500</td>\n","      <td>0.163093</td>\n","      <td>0.970822</td>\n","      <td>0.924242</td>\n","      <td>0.946960</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1425' max='1425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1425/1425 02:58, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.617600</td>\n","      <td>0.513711</td>\n","      <td>0.747631</td>\n","      <td>0.713229</td>\n","      <td>0.730025</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.372300</td>\n","      <td>0.264214</td>\n","      <td>0.965251</td>\n","      <td>0.821693</td>\n","      <td>0.887705</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.217000</td>\n","      <td>0.234219</td>\n","      <td>0.951818</td>\n","      <td>0.860312</td>\n","      <td>0.903755</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.170200</td>\n","      <td>0.176516</td>\n","      <td>0.972493</td>\n","      <td>0.900575</td>\n","      <td>0.935154</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.113400</td>\n","      <td>0.183264</td>\n","      <td>0.967430</td>\n","      <td>0.903040</td>\n","      <td>0.934127</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_4000/Dump/res/checkpoint-1425 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:185: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  test_metrics_df = test_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test F1: 0.9292717086834733\n","{'bug report': {'precision': 0.9892086330935251, 'recall': 0.9548611111111112, 'f1-score': 0.9717314487632509, 'support': 288}, 'user experience': {'precision': 0.9503424657534246, 'recall': 0.9422750424448217, 'f1-score': 0.9462915601023018, 'support': 589}, 'rating': {'precision': 0.883495145631068, 'recall': 0.708171206225681, 'f1-score': 0.7861771058315334, 'support': 257}, 'feature request': {'precision': 0.9905660377358491, 'recall': 0.9375, 'f1-score': 0.963302752293578, 'support': 336}, 'micro avg': {'precision': 0.9574314574314574, 'recall': 0.9027210884353741, 'f1-score': 0.9292717086834733, 'support': 1470}, 'macro avg': {'precision': 0.9534030705534667, 'recall': 0.8857018399454035, 'f1-score': 0.916875716747666, 'support': 1470}, 'weighted avg': {'precision': 0.9554641086844435, 'recall': 0.9027210884353741, 'f1-score': 0.9271711749070873, 'support': 1470}, 'samples avg': {'precision': 0.8715625, 'recall': 0.83375, 'f1-score': 0.8418869047619048, 'support': 1470}}\n"]}],"source":["print(f\"Now doing: {files_multi_label[1][0].split('.')[0]}\")\n","multi_main_model(files_multi_label[1][0].split('.')[0], files_multi_label[1][0].split('.')[1])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4964955,"status":"ok","timestamp":1709601357966,"user":{"displayName":"Pavel Ghazaryan","userId":"06174483014484084828"},"user_tz":0},"id":"6YjUnUycNiyA","outputId":"c0c55c07-45fd-485a-ddad-b59293609269"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now doing: dataset_gpt_multi_label_8000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:25, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.459500</td>\n","      <td>0.215340</td>\n","      <td>0.969062</td>\n","      <td>0.872025</td>\n","      <td>0.917986</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.161200</td>\n","      <td>0.116893</td>\n","      <td>0.991388</td>\n","      <td>0.930400</td>\n","      <td>0.959926</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.101000</td>\n","      <td>0.096948</td>\n","      <td>0.996216</td>\n","      <td>0.945667</td>\n","      <td>0.970283</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.078000</td>\n","      <td>0.096862</td>\n","      <td>0.983759</td>\n","      <td>0.951953</td>\n","      <td>0.967595</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.059900</td>\n","      <td>0.089913</td>\n","      <td>0.984252</td>\n","      <td>0.954198</td>\n","      <td>0.968992</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:25, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.468400</td>\n","      <td>0.197522</td>\n","      <td>0.987888</td>\n","      <td>0.862529</td>\n","      <td>0.920962</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.159700</td>\n","      <td>0.134471</td>\n","      <td>0.978754</td>\n","      <td>0.931954</td>\n","      <td>0.954781</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.105600</td>\n","      <td>0.123352</td>\n","      <td>0.978032</td>\n","      <td>0.941609</td>\n","      <td>0.959475</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.081700</td>\n","      <td>0.114740</td>\n","      <td>0.971254</td>\n","      <td>0.947586</td>\n","      <td>0.959274</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.064000</td>\n","      <td>0.109935</td>\n","      <td>0.982356</td>\n","      <td>0.947126</td>\n","      <td>0.964419</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:28, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.466900</td>\n","      <td>0.195888</td>\n","      <td>0.998908</td>\n","      <td>0.854673</td>\n","      <td>0.921179</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.160000</td>\n","      <td>0.127452</td>\n","      <td>0.983226</td>\n","      <td>0.931308</td>\n","      <td>0.956563</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.095800</td>\n","      <td>0.106649</td>\n","      <td>0.975036</td>\n","      <td>0.949065</td>\n","      <td>0.961875</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.069600</td>\n","      <td>0.098168</td>\n","      <td>0.985929</td>\n","      <td>0.949533</td>\n","      <td>0.967389</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.049200</td>\n","      <td>0.104324</td>\n","      <td>0.980250</td>\n","      <td>0.950935</td>\n","      <td>0.965370</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.469900</td>\n","      <td>0.205610</td>\n","      <td>0.981413</td>\n","      <td>0.865574</td>\n","      <td>0.919861</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.163200</td>\n","      <td>0.137907</td>\n","      <td>0.973145</td>\n","      <td>0.933489</td>\n","      <td>0.952905</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.107000</td>\n","      <td>0.110024</td>\n","      <td>0.974026</td>\n","      <td>0.948478</td>\n","      <td>0.961082</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.072900</td>\n","      <td>0.092567</td>\n","      <td>0.980788</td>\n","      <td>0.956440</td>\n","      <td>0.968461</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.051200</td>\n","      <td>0.095714</td>\n","      <td>0.979367</td>\n","      <td>0.955972</td>\n","      <td>0.967528</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2845' max='2845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2845/2845 05:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.466400</td>\n","      <td>0.204564</td>\n","      <td>0.995590</td>\n","      <td>0.857143</td>\n","      <td>0.921194</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.159600</td>\n","      <td>0.124656</td>\n","      <td>0.986869</td>\n","      <td>0.927385</td>\n","      <td>0.956203</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.111200</td>\n","      <td>0.113902</td>\n","      <td>0.986007</td>\n","      <td>0.936402</td>\n","      <td>0.960565</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.079700</td>\n","      <td>0.111013</td>\n","      <td>0.980411</td>\n","      <td>0.950166</td>\n","      <td>0.965052</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.058700</td>\n","      <td>0.105456</td>\n","      <td>0.973837</td>\n","      <td>0.953963</td>\n","      <td>0.963798</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_8000/Dump/res/checkpoint-2845 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:185: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  test_metrics_df = test_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test F1: 0.9672544080604534\n","{'bug report': {'precision': 0.9919028340080972, 'recall': 0.9702970297029703, 'f1-score': 0.980980980980981, 'support': 505}, 'user experience': {'precision': 0.9952516619183286, 'recall': 0.9579524680073126, 'f1-score': 0.976245924545878, 'support': 1094}, 'rating': {'precision': 0.9974293059125964, 'recall': 0.8308351177730193, 'f1-score': 0.9065420560747663, 'support': 467}, 'feature request': {'precision': 0.9965034965034965, 'recall': 0.9710391822827938, 'f1-score': 0.9836065573770492, 'support': 587}, 'micro avg': {'precision': 0.9952153110047847, 'recall': 0.94082171127026, 'f1-score': 0.9672544080604534, 'support': 2653}, 'macro avg': {'precision': 0.9952718245856296, 'recall': 0.932530949441524, 'f1-score': 0.9618438797446687, 'support': 2653}, 'weighted avg': {'precision': 0.9952745147461273, 'recall': 0.94082171127026, 'f1-score': 0.9665060784831622, 'support': 2653}, 'samples avg': {'precision': 0.8693229166666666, 'recall': 0.8405208333333333, 'f1-score': 0.8501160714285715, 'support': 2653}}\n","Now doing: dataset_gpt_multi_label_16000\n","Fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:31, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.297900</td>\n","      <td>0.091121</td>\n","      <td>0.989359</td>\n","      <td>0.948718</td>\n","      <td>0.968612</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.088800</td>\n","      <td>0.087214</td>\n","      <td>0.982086</td>\n","      <td>0.961015</td>\n","      <td>0.971436</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.061000</td>\n","      <td>0.050754</td>\n","      <td>0.991478</td>\n","      <td>0.974097</td>\n","      <td>0.982711</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.036900</td>\n","      <td>0.046803</td>\n","      <td>0.995461</td>\n","      <td>0.975406</td>\n","      <td>0.985331</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.026800</td>\n","      <td>0.052539</td>\n","      <td>0.987308</td>\n","      <td>0.976975</td>\n","      <td>0.982115</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.278300</td>\n","      <td>0.106358</td>\n","      <td>0.987634</td>\n","      <td>0.938626</td>\n","      <td>0.962507</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.078900</td>\n","      <td>0.081122</td>\n","      <td>0.993735</td>\n","      <td>0.952729</td>\n","      <td>0.972800</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.050800</td>\n","      <td>0.058534</td>\n","      <td>0.993031</td>\n","      <td>0.967616</td>\n","      <td>0.980159</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.034300</td>\n","      <td>0.055902</td>\n","      <td>0.989888</td>\n","      <td>0.971533</td>\n","      <td>0.980625</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.023300</td>\n","      <td>0.057866</td>\n","      <td>0.989113</td>\n","      <td>0.972839</td>\n","      <td>0.980908</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.283200</td>\n","      <td>0.093298</td>\n","      <td>0.985592</td>\n","      <td>0.954275</td>\n","      <td>0.969681</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.078200</td>\n","      <td>0.055596</td>\n","      <td>0.993145</td>\n","      <td>0.973134</td>\n","      <td>0.983038</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.044900</td>\n","      <td>0.054748</td>\n","      <td>0.990816</td>\n","      <td>0.975459</td>\n","      <td>0.983077</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.032100</td>\n","      <td>0.049632</td>\n","      <td>0.993170</td>\n","      <td>0.976750</td>\n","      <td>0.984892</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.022500</td>\n","      <td>0.052011</td>\n","      <td>0.992653</td>\n","      <td>0.977267</td>\n","      <td>0.984900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:13, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.288300</td>\n","      <td>0.104328</td>\n","      <td>0.978842</td>\n","      <td>0.955590</td>\n","      <td>0.967076</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.076900</td>\n","      <td>0.060470</td>\n","      <td>0.995222</td>\n","      <td>0.967983</td>\n","      <td>0.981414</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.046800</td>\n","      <td>0.057687</td>\n","      <td>0.985912</td>\n","      <td>0.975729</td>\n","      <td>0.980794</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.032400</td>\n","      <td>0.061688</td>\n","      <td>0.982333</td>\n","      <td>0.976246</td>\n","      <td>0.979280</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.022100</td>\n","      <td>0.057681</td>\n","      <td>0.986198</td>\n","      <td>0.977795</td>\n","      <td>0.981978</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Fold 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5690' max='5690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5690/5690 10:16, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.288100</td>\n","      <td>0.110935</td>\n","      <td>0.979575</td>\n","      <td>0.944838</td>\n","      <td>0.961893</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.080800</td>\n","      <td>0.069113</td>\n","      <td>0.996459</td>\n","      <td>0.960862</td>\n","      <td>0.978336</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.050900</td>\n","      <td>0.059379</td>\n","      <td>0.991398</td>\n","      <td>0.968742</td>\n","      <td>0.979939</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.036400</td>\n","      <td>0.060018</td>\n","      <td>0.990892</td>\n","      <td>0.971631</td>\n","      <td>0.981167</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.025500</td>\n","      <td>0.061204</td>\n","      <td>0.989322</td>\n","      <td>0.973470</td>\n","      <td>0.981332</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","Checkpoint destination directory /content/drive/MyDrive/FinalProject/Models/BART/Output/Multi-label/dataset_gpt_multi_label_16000/Dump/res/checkpoint-5690 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight'].\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:148: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  metrics_df = metrics_df.append({\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-4-3935eeb31289>:185: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  test_metrics_df = test_metrics_df.append({\n"]},{"name":"stdout","output_type":"stream","text":["Test F1: 0.9824748877965378\n","{'bug report': {'precision': 0.9910714285714286, 'recall': 0.9833887043189369, 'f1-score': 0.9872151195108393, 'support': 903}, 'user experience': {'precision': 0.9975272007912958, 'recall': 0.9786511402231927, 'f1-score': 0.9879990203281901, 'support': 2061}, 'rating': {'precision': 0.9871060171919771, 'recall': 0.9223560910307899, 'f1-score': 0.9536332179930795, 'support': 747}, 'feature request': {'precision': 0.9960278053624627, 'recall': 0.9794921875, 'f1-score': 0.9876907927129492, 'support': 1024}, 'micro avg': {'precision': 0.9943759463551807, 'recall': 0.9708553326293559, 'f1-score': 0.9824748877965378, 'support': 4735}, 'macro avg': {'precision': 0.992933112979291, 'recall': 0.9659720307682298, 'f1-score': 0.9791345376362646, 'support': 4735}, 'weighted avg': {'precision': 0.9943277145437022, 'recall': 0.9708553326293559, 'f1-score': 0.9823612712552435, 'support': 4735}, 'samples avg': {'precision': 0.8453385416666666, 'recall': 0.83515625, 'f1-score': 0.8381755952380953, 'support': 4735}}\n"]}],"source":["print(f\"Now doing: {files_multi_label[2][0].split('.')[0]}\")\n","multi_main_model(files_multi_label[2][0].split('.')[0], files_multi_label[2][0].split('.')[1])\n","print(f\"Now doing: {files_multi_label[3][0].split('.')[0]}\")\n","multi_main_model(files_multi_label[3][0].split('.')[0], files_multi_label[3][0].split('.')[1])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"004af2b73f0c426c8c4839b62148d3bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4904c5d93edf418eb366a0cf874ff23c","IPY_MODEL_ddc96509c8f24f298f74be370a3d9faf","IPY_MODEL_d8ddc8ef4dc3499fb1b198096b6cd3c8"],"layout":"IPY_MODEL_f7f0f613881e44a1a5e79bf8dafe4d17"}},"00a6052def7e4197a5c5b1b0b45803ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f360a218292348f4b6814bce5f353d47","IPY_MODEL_b6cffae2d83b418898ff8276655ecedb","IPY_MODEL_2edbccc5200240f2a81d3c61a2cbe04d"],"layout":"IPY_MODEL_7cdb4d0ccaf643a599e55874f2c12ceb"}},"05d88a634bdb456aa9e06d7a42b70627":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06fa750077c544c5bc3a3d33c3dd2563":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0707517a0ca74fb09b8fbec03f3404b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d815cbbb62c74dfcb0ad786e16471e49","placeholder":"​","style":"IPY_MODEL_0f52c2459c5d4d45b6fd694a1ee6d3cf","value":"merges.txt: 100%"}},"07e574af52bd446cbd1da4e2613cbfdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0854e8b45bc54b3b89c27e7e157910af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08aa6a7467cf43db86b52c84af725447":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41885922f89a43709b98cfac38cea421","placeholder":"​","style":"IPY_MODEL_74cf6dd0943c496a81674f82b3607e1b","value":" 1.72k/1.72k [00:00&lt;00:00, 165kB/s]"}},"08c4b3372b2247de822229cddc2175e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a27ae4897ca4219b0f44f6cf5aac8ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdc9bfbc9af0450e95e039f01982b22a","placeholder":"​","style":"IPY_MODEL_1be9dfb5536f4880980c64dc8bca5169","value":"merges.txt: 100%"}},"0d71d99ab2154b7fb8ab08738f2c71d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_866b8e75fe7a491a8f36406c1896f8bd","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd43da46a47e48fba2f51b3a1599ffd6","value":456318}},"0de29eb276804915acbaf426b0e5fa3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eb08ebc0d8a44ddbf1e617aca90d6df","placeholder":"​","style":"IPY_MODEL_623273a25db94d98830014e5abd7aea3","value":"vocab.json: 100%"}},"0dfecee3c93249218bed9c7995916acf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f444c0b446e4555809ba97ae3f7873a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f52c2459c5d4d45b6fd694a1ee6d3cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f764ad634eb4a35ac483aede445975b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fecc90cafd9478b801ea2e65197765e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e676320994543f0b7da6329de484c89","placeholder":"​","style":"IPY_MODEL_7a00f7bc8c9746febd867a9e36553f16","value":"config.json: 100%"}},"107fc1d57c554098b322b07013534152":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"111aac1c928c434aa170ef74f09197fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"125fc0db75e14a1a8afde77445cd7408":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a7be63dce943bea53f3ecddca26b5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_633e140611e44e07bc0a9146813e5420","placeholder":"​","style":"IPY_MODEL_b8bdda7a3b2b4d3f897dcf56097b39c6","value":" 899k/899k [00:00&lt;00:00, 6.67MB/s]"}},"155cddcefaba432f9d6d57e868c64a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15a881438f904d54824ad47ecec06c1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1604639d52c84c83b473021edf8529f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"165e2cb18baa4ebba0e0c6b77f11d135":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"168ac6fb08aa45c28df2323810795b89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17ba83d2fec24b92bce7cf78081c8462":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d5ba59379fb4d68b4c8cda77fcffb6d","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6890bcadefb4ed89ed58db06dfbd070","value":1355863}},"1b06a6e151944455bfea0b89331b95c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4a9e96fdf414b018ff81ce55a3f646b","IPY_MODEL_4c294211d3f446108a5ea3599a9ce08a","IPY_MODEL_d3119dfd42a041618d55ff6276bd2ea6"],"layout":"IPY_MODEL_66ed1574eae942fe9a304bbdb34f8865"}},"1b1525f161c24137b8bc19ec88abc821":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1be9dfb5536f4880980c64dc8bca5169":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ed3ac9c8e70457e9e1f6b2de53b9b4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"200007a05e33493bbf75c849db809709":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_896827fe1a1d4e9abfc0344ac502ba05","IPY_MODEL_a351e9b58d644cb4ad35159b64d2be11","IPY_MODEL_dac0a49c448248458c80b5dfc446d3d1"],"layout":"IPY_MODEL_466c8de504474f9f9197aea9bc698fa9"}},"207fdd678a8d4c56b75b4ba9a6aa0da1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21abafe318344343ae9c2dae4ac9229c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21d1d695d85a498193e807685b3d659c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2257e510e82847ee84c7e96d4cfa531b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23456a92e6e84583b27615814a0ccdc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"274bfda4e20b4a62966af1ec40804224":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2816e196a7664c99ab3d6670c5eaa50d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"283988d928a847c892d9d07baff221dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a5182a4dcfb45f0a51dad40392ccb60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a96de1958a94386b38ff85552045a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdc68768388f4d2baa096eb78a27f027","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4136e7f3caab45519129891cbc3ec2c4","value":1355863}},"2b8f665439dd497e9675163862e4dba2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99547acaf44d4e83b16d2410963586d2","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a17f52d2220e4f1597b2c6ce6bbc22ce","value":557709915}},"2bd6788c5e0541e48b8fbaf2fa2846cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c5b85e076a74ba780cae05d42368f8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da35f86b6de2423497d60f48d39fddde","IPY_MODEL_17ba83d2fec24b92bce7cf78081c8462","IPY_MODEL_3c004a13999347ecbba15ddc11e8e203"],"layout":"IPY_MODEL_85e413a91a904490a6de0bee98510aec"}},"2cc220d33f4a481298c67a3746fecf0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d23fa49ee9d4841a43794d79d129256":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5182a4dcfb45f0a51dad40392ccb60","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d518cf8ac2e494e9a0b877a8ab25953","value":1355863}},"2d5ba59379fb4d68b4c8cda77fcffb6d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edbccc5200240f2a81d3c61a2cbe04d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba11b77eb5d749248154d79ab86142b6","placeholder":"​","style":"IPY_MODEL_6eec4062eb154eaf892b9c03e960e63b","value":" 456k/456k [00:00&lt;00:00, 34.5MB/s]"}},"2ee62a093c6045ba868c71817b398b0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a27ae4897ca4219b0f44f6cf5aac8ec","IPY_MODEL_8bf6d39a2f604cbdba86f720ad4fd89c","IPY_MODEL_b1d1f35c0ae44dc09fe5af0641851cb2"],"layout":"IPY_MODEL_f91b4511e70f4ac498d1cefaa9d1b565"}},"30c9ed9d93564932a9d0316d8f52ed9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"312f1e25adc64740ae264250cecab3fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3335800dba854fccb6f1ac21b1cf0915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a4352a6214496ab1b54c7ef39d7ba3","placeholder":"​","style":"IPY_MODEL_f684acff1ee8456c901b3534d8d1d3b9","value":" 558M/558M [00:29&lt;00:00, 19.4MB/s]"}},"347414beb90e4da891833b53a59077dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f5ab8316fd426789c145f9ee740138","IPY_MODEL_2b8f665439dd497e9675163862e4dba2","IPY_MODEL_3335800dba854fccb6f1ac21b1cf0915"],"layout":"IPY_MODEL_b029dd8d86ee4fad8515292818e1b16c"}},"35db0ffe4c974f63bd6b38edb6636c03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2816e196a7664c99ab3d6670c5eaa50d","placeholder":"​","style":"IPY_MODEL_774de44ea7d749b48409beb8ddbc44e9","value":" 1.36M/1.36M [00:00&lt;00:00, 4.11MB/s]"}},"37fc7d2ec0a74bebb96f9db1c0b21ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38d04fcd21024fe4b3a9bf127dc5d945":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39d13f90570444418600206e711975f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c004a13999347ecbba15ddc11e8e203":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44b695f128824178b7f75dbf6e331d37","placeholder":"​","style":"IPY_MODEL_312f1e25adc64740ae264250cecab3fe","value":" 1.36M/1.36M [00:00&lt;00:00, 39.5MB/s]"}},"3c776864e4bd46e6b5e35d6de57b34c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f179040323834b8a82dd10283036e6da","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4fd6031f51d4a94864b57b28c07610c","value":1716}},"4136e7f3caab45519129891cbc3ec2c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41885922f89a43709b98cfac38cea421":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41c4b423c432490c8fb1ec0d00f6928d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42c8635a5d5d4d1496072b8fcf28acc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42cdc65822b34fa1a34b0e57a7f32670":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fecc90cafd9478b801ea2e65197765e","IPY_MODEL_3c776864e4bd46e6b5e35d6de57b34c7","IPY_MODEL_5b9947ebccf643179a41a0348bc50877"],"layout":"IPY_MODEL_7fe6f45983f44762b789586392bbd905"}},"442d4495dfcf422dbd92873f1d4bf6d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b695f128824178b7f75dbf6e331d37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4579414e56ea418d92144c8a8fa043ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"459e3aa0608e405cb9eaafecb2a671f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_165e2cb18baa4ebba0e0c6b77f11d135","placeholder":"​","style":"IPY_MODEL_a3f5df8538cd488da8a36ae4d6b783e1","value":" 1.36M/1.36M [00:00&lt;00:00, 4.20MB/s]"}},"466c8de504474f9f9197aea9bc698fa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"479d73bbb8614ae596ad95d7114e8fd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48dcbef944b54184a6e23361cce6c69b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4904c5d93edf418eb366a0cf874ff23c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca362e1730d9441283a7efe24fa8404b","placeholder":"​","style":"IPY_MODEL_155cddcefaba432f9d6d57e868c64a15","value":"vocab.json: 100%"}},"4c294211d3f446108a5ea3599a9ce08a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9337bfcba7c1453a973e543e5c9c7bd1","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23456a92e6e84583b27615814a0ccdc0","value":1355863}},"4cdadc5afa3449f49b86a65ad9a23638":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e676320994543f0b7da6329de484c89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e795fd86660407e84cb0251446f3a2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f49e20038664cb78c4ef0865aae880d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07e574af52bd446cbd1da4e2613cbfdc","placeholder":"​","style":"IPY_MODEL_65cc9f04470a46bb80363a62071a9e27","value":" 1.72k/1.72k [00:00&lt;00:00, 148kB/s]"}},"4f880704aecb4ebbbaf696c97afed1cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4579414e56ea418d92144c8a8fa043ce","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4ec49665e3445ccb04f89139f07a234","value":1716}},"502957b87dda49ec8a0f2067be680cb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50a4352a6214496ab1b54c7ef39d7ba3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"528a949ce640410daff9d18934d91775":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73111060649547aa99e8d2654d7fa52c","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1604639d52c84c83b473021edf8529f7","value":557709915}},"5757f7049bcc44b382374bc87f8ab0a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"580006a106d14a208d5595fb5303824e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b5d345ee994e848a106bbe78ccfc3b","placeholder":"​","style":"IPY_MODEL_39d13f90570444418600206e711975f2","value":" 899k/899k [00:00&lt;00:00, 1.13MB/s]"}},"58514e3c432f409f8c92bbb0b2973407":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"587f763a523e44f3b38a25111694b9dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"596f5836ffae491faa020e9e144fa385":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad19e8e20d2842af86d1fbcf0dbc4cd7","placeholder":"​","style":"IPY_MODEL_98992f22604b4238af8a6bf99fa644d1","value":"vocab.json: 100%"}},"5b9947ebccf643179a41a0348bc50877":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_125fc0db75e14a1a8afde77445cd7408","placeholder":"​","style":"IPY_MODEL_a7b0f54872e64eb085fe44d46fb0e584","value":" 1.72k/1.72k [00:00&lt;00:00, 135kB/s]"}},"5e1a2f616c76479faf675e0d3abacbb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"623273a25db94d98830014e5abd7aea3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"633e140611e44e07bc0a9146813e5420":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6352bb5c22d74d5a943648793b01eccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65cc9f04470a46bb80363a62071a9e27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66ed1574eae942fe9a304bbdb34f8865":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6733a3ceae704c88a35039236f466841":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"676a4bd9ad1440868e319bb9abd733f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68eef1114f8e4946b5b917f7fa040d37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff4714100f0f40f59587ef35aba8f451","placeholder":"​","style":"IPY_MODEL_e0d14f134cd9483885cf1582bd54cff1","value":" 558M/558M [00:01&lt;00:00, 371MB/s]"}},"692c194bca1f4ba4b394f4e2b71f8f7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6930125dc9cf45df9012789bb00342f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b554276e78b46e1b95d01353b147fc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4339f891a3f474c8102a1827b48ab47","IPY_MODEL_97e4adbf14af45f4b89cf7013f4bb0d0","IPY_MODEL_580006a106d14a208d5595fb5303824e"],"layout":"IPY_MODEL_ce0231b9cea841b9ab05b09039ce3661"}},"6ce4a8c2e5424624ad6770c8ae9404dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e2d6a77eeb9467b956f5ae65dc22d71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6eec4062eb154eaf892b9c03e960e63b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70547ca26b6544f7a9e59116c4af1416":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e795fd86660407e84cb0251446f3a2e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d26ae8a6ba0d405ca4113339440cb564","value":456318}},"71f7866e0be94664a2115478041799bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73111060649547aa99e8d2654d7fa52c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74cf6dd0943c496a81674f82b3607e1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74d15072448f47eeb0790fd39c797ce2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8254fc31b034d0a879d3a9aca628084","placeholder":"​","style":"IPY_MODEL_f4c11eee9c064a229c4292861a7cce8a","value":" 456k/456k [00:00&lt;00:00, 2.50MB/s]"}},"74ee73a51d614ff8bd895fe86781e10c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf1802e72e8444ce8b4b83120f4248cf","IPY_MODEL_89b4e6584a15447594eb60a5b0748745","IPY_MODEL_8a1ea3a2f289416190e83b076359bc13"],"layout":"IPY_MODEL_38d04fcd21024fe4b3a9bf127dc5d945"}},"767b0bb35cce4a55a93f6b2459e4666b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71f7866e0be94664a2115478041799bc","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f444c0b446e4555809ba97ae3f7873a","value":898823}},"770f97909cce468c92aa5fc0e9941dbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"774de44ea7d749b48409beb8ddbc44e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a00f7bc8c9746febd867a9e36553f16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c5fa0df1f0641fc856f52f33c1baba7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cdb4d0ccaf643a599e55874f2c12ceb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d518cf8ac2e494e9a0b877a8ab25953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e28f0f4b7404929a37fc25ca251e40f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb08ebc0d8a44ddbf1e617aca90d6df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fe6f45983f44762b789586392bbd905":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b2e26145d744998c78ce1b8689b582":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83224023d36945f8b8ee0e12411f058b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d1c053d7e44120ab6ae7919310298c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85788fd36887493e8a6796b17afb2dd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cc220d33f4a481298c67a3746fecf0a","placeholder":"​","style":"IPY_MODEL_c9ce96a96dbc4662ab90f07f6e9a86ee","value":"config.json: 100%"}},"85e413a91a904490a6de0bee98510aec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866b8e75fe7a491a8f36406c1896f8bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"896827fe1a1d4e9abfc0344ac502ba05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83224023d36945f8b8ee0e12411f058b","placeholder":"​","style":"IPY_MODEL_06fa750077c544c5bc3a3d33c3dd2563","value":"model.safetensors: 100%"}},"89b4e6584a15447594eb60a5b0748745":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c5fa0df1f0641fc856f52f33c1baba7","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0854e8b45bc54b3b89c27e7e157910af","value":557709915}},"89be7c09ebce4b7597643fddf5ac2c5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1ea3a2f289416190e83b076359bc13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad674b1e578a49548952386fccdf875e","placeholder":"​","style":"IPY_MODEL_41c4b423c432490c8fb1ec0d00f6928d","value":" 558M/558M [00:02&lt;00:00, 271MB/s]"}},"8bf6d39a2f604cbdba86f720ad4fd89c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d62378b8364c4da5e8479eece0f0d7","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bab5ee18ec1430390ec4554c02e1322","value":456318}},"8c67b6e87c8048a1b5549b6bcccbf2dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b525f9a501584cda8e0a3b4dba75d92e","IPY_MODEL_8e12211a5ebb4de3b26efca80e7eccfa","IPY_MODEL_9331b9c35e514250a9d9b224853af659"],"layout":"IPY_MODEL_9f42e0ab7d224b23b263e3f445d81d9d"}},"8e12211a5ebb4de3b26efca80e7eccfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48dcbef944b54184a6e23361cce6c69b","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6930125dc9cf45df9012789bb00342f0","value":1716}},"8edc9f07113d4b94983d6b72043888ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe5175087a2403a80f7273445a19122":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91aae9dd78d5407aa13a29a272f98810":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3de702f9af648c69e5c7c04d8d637e0","placeholder":"​","style":"IPY_MODEL_ae9b3ce2408a48a38ae96835ade0a3fb","value":"tokenizer.json: 100%"}},"9331b9c35e514250a9d9b224853af659":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a137e811f00648ccbd73f2854012397f","placeholder":"​","style":"IPY_MODEL_b2bee341f6ad42c384d2488885ff2c4b","value":" 1.72k/1.72k [00:00&lt;00:00, 111kB/s]"}},"9337bfcba7c1453a973e543e5c9c7bd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94338236b8dd4fc3bd04fe04ff27e2ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2d4bc4629e344b3bbcbaa70f1f46fa3","IPY_MODEL_0d71d99ab2154b7fb8ab08738f2c71d2","IPY_MODEL_dc31769949904f51aa100ee3a40e0c67"],"layout":"IPY_MODEL_ffe8124e1bef4c29a3404077f87307ba"}},"95bdeac851904c1b92af09bc625ef62a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0707517a0ca74fb09b8fbec03f3404b4","IPY_MODEL_70547ca26b6544f7a9e59116c4af1416","IPY_MODEL_74d15072448f47eeb0790fd39c797ce2"],"layout":"IPY_MODEL_7e28f0f4b7404929a37fc25ca251e40f"}},"97e4adbf14af45f4b89cf7013f4bb0d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe5175087a2403a80f7273445a19122","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80b2e26145d744998c78ce1b8689b582","value":898823}},"98992f22604b4238af8a6bf99fa644d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99059350bb5d4276be6e9466401bf0f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99547acaf44d4e83b16d2410963586d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bab5ee18ec1430390ec4554c02e1322":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f42e0ab7d224b23b263e3f445d81d9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a137e811f00648ccbd73f2854012397f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a17f52d2220e4f1597b2c6ce6bbc22ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a351e9b58d644cb4ad35159b64d2be11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd6788c5e0541e48b8fbaf2fa2846cb","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_274bfda4e20b4a62966af1ec40804224","value":557709915}},"a3f5df8538cd488da8a36ae4d6b783e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a41d8d368b1a4ff9bfbad465cc308f88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6248a34418342419a76a7890a8f74d6","IPY_MODEL_528a949ce640410daff9d18934d91775","IPY_MODEL_68eef1114f8e4946b5b917f7fa040d37"],"layout":"IPY_MODEL_1b1525f161c24137b8bc19ec88abc821"}},"a56c904aa53347d496af04862be1748f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d1c053d7e44120ab6ae7919310298c","placeholder":"​","style":"IPY_MODEL_479d73bbb8614ae596ad95d7114e8fd5","value":"config.json: 100%"}},"a7b0f54872e64eb085fe44d46fb0e584":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7d62378b8364c4da5e8479eece0f0d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a805b6e6c60941f699672f9f2827c159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91aae9dd78d5407aa13a29a272f98810","IPY_MODEL_2a96de1958a94386b38ff85552045a9c","IPY_MODEL_35db0ffe4c974f63bd6b38edb6636c03"],"layout":"IPY_MODEL_207fdd678a8d4c56b75b4ba9a6aa0da1"}},"a8254fc31b034d0a879d3a9aca628084":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab61a05477124cc095c926afb85c2ebd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_596f5836ffae491faa020e9e144fa385","IPY_MODEL_c83137d0e09f488f89956a8d6d465c0b","IPY_MODEL_13a7be63dce943bea53f3ecddca26b5e"],"layout":"IPY_MODEL_1ed3ac9c8e70457e9e1f6b2de53b9b4c"}},"ad19e8e20d2842af86d1fbcf0dbc4cd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad674b1e578a49548952386fccdf875e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae9b3ce2408a48a38ae96835ade0a3fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b029dd8d86ee4fad8515292818e1b16c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c0ec4a95d94eb4baf41ccfe6c1e0e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1d1f35c0ae44dc09fe5af0641851cb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f764ad634eb4a35ac483aede445975b","placeholder":"​","style":"IPY_MODEL_6e2d6a77eeb9467b956f5ae65dc22d71","value":" 456k/456k [00:00&lt;00:00, 767kB/s]"}},"b2bee341f6ad42c384d2488885ff2c4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2d4bc4629e344b3bbcbaa70f1f46fa3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dfecee3c93249218bed9c7995916acf","placeholder":"​","style":"IPY_MODEL_99059350bb5d4276be6e9466401bf0f0","value":"merges.txt: 100%"}},"b3de702f9af648c69e5c7c04d8d637e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b525f9a501584cda8e0a3b4dba75d92e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5757f7049bcc44b382374bc87f8ab0a4","placeholder":"​","style":"IPY_MODEL_c53bd76043a348b184e6b7873c9bf365","value":"config.json: 100%"}},"b5f5ab8316fd426789c145f9ee740138":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_676a4bd9ad1440868e319bb9abd733f8","placeholder":"​","style":"IPY_MODEL_4cdadc5afa3449f49b86a65ad9a23638","value":"model.safetensors: 100%"}},"b6cffae2d83b418898ff8276655ecedb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2993dedbd0b4805adfbe6d400cbce2d","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef8b68ae53724392b0f075cf4f9ad445","value":456318}},"b70ac8c1d1154c84abc64256126e80b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ae5bfb76454a23897baa48f941f72d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37fc7d2ec0a74bebb96f9db1c0b21ee0","placeholder":"​","style":"IPY_MODEL_21abafe318344343ae9c2dae4ac9229c","value":" 899k/899k [00:00&lt;00:00, 2.79MB/s]"}},"b8bdda7a3b2b4d3f897dcf56097b39c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba11b77eb5d749248154d79ab86142b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbc292ecfb4941a7869177f774b43a1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc390ead714e4413b134e7d3b6d46e25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce4a8c2e5424624ad6770c8ae9404dd","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f98326afd2734c0c9d2cdc4c1aaddb03","value":1716}},"bdc68768388f4d2baa096eb78a27f027":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c24ed5712a254bedb185b1a47159f056":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2993dedbd0b4805adfbe6d400cbce2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c53bd76043a348b184e6b7873c9bf365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6890bcadefb4ed89ed58db06dfbd070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c83137d0e09f488f89956a8d6d465c0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_692c194bca1f4ba4b394f4e2b71f8f7a","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2257e510e82847ee84c7e96d4cfa531b","value":898823}},"c9ce96a96dbc4662ab90f07f6e9a86ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca362e1730d9441283a7efe24fa8404b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd43da46a47e48fba2f51b3a1599ffd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd682addc8544596aef1c53f1887c5f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0e8e94b3d254794a8f697922e256a73","IPY_MODEL_2d23fa49ee9d4841a43794d79d129256","IPY_MODEL_459e3aa0608e405cb9eaafecb2a671f3"],"layout":"IPY_MODEL_b1c0ec4a95d94eb4baf41ccfe6c1e0e5"}},"cdc9bfbc9af0450e95e039f01982b22a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce0231b9cea841b9ab05b09039ce3661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1802e72e8444ce8b4b83120f4248cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_168ac6fb08aa45c28df2323810795b89","placeholder":"​","style":"IPY_MODEL_58514e3c432f409f8c92bbb0b2973407","value":"model.safetensors: 100%"}},"d26ae8a6ba0d405ca4113339440cb564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3119dfd42a041618d55ff6276bd2ea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_502957b87dda49ec8a0f2067be680cb4","placeholder":"​","style":"IPY_MODEL_42c8635a5d5d4d1496072b8fcf28acc3","value":" 1.36M/1.36M [00:00&lt;00:00, 1.70MB/s]"}},"d6b6d2978f4c413481ba47c2a4ec2bb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d815cbbb62c74dfcb0ad786e16471e49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8ddc8ef4dc3499fb1b198096b6cd3c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30c9ed9d93564932a9d0316d8f52ed9c","placeholder":"​","style":"IPY_MODEL_dea4ac9ac1d9424f87fad1fc9312c863","value":" 899k/899k [00:00&lt;00:00, 12.6MB/s]"}},"da35f86b6de2423497d60f48d39fddde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f31de05417254d68baae9567a0272df1","placeholder":"​","style":"IPY_MODEL_111aac1c928c434aa170ef74f09197fd","value":"tokenizer.json: 100%"}},"dac0a49c448248458c80b5dfc446d3d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6733a3ceae704c88a35039236f466841","placeholder":"​","style":"IPY_MODEL_770f97909cce468c92aa5fc0e9941dbc","value":" 558M/558M [00:02&lt;00:00, 280MB/s]"}},"dc31769949904f51aa100ee3a40e0c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05d88a634bdb456aa9e06d7a42b70627","placeholder":"​","style":"IPY_MODEL_ef7b03d126564b66a0644bfd937aeac3","value":" 456k/456k [00:00&lt;00:00, 1.85MB/s]"}},"dd5b225e19034e28b311d73360c0163d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85788fd36887493e8a6796b17afb2dd6","IPY_MODEL_bc390ead714e4413b134e7d3b6d46e25","IPY_MODEL_4f49e20038664cb78c4ef0865aae880d"],"layout":"IPY_MODEL_15a881438f904d54824ad47ecec06c1e"}},"ddc96509c8f24f298f74be370a3d9faf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8edc9f07113d4b94983d6b72043888ca","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_283988d928a847c892d9d07baff221dd","value":898823}},"dea4ac9ac1d9424f87fad1fc9312c863":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0d14f134cd9483885cf1582bd54cff1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e49de008fb6d4bdc92a6e9c329d59ff0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0de29eb276804915acbaf426b0e5fa3f","IPY_MODEL_767b0bb35cce4a55a93f6b2459e4666b","IPY_MODEL_b7ae5bfb76454a23897baa48f941f72d"],"layout":"IPY_MODEL_587f763a523e44f3b38a25111694b9dc"}},"e4a9e96fdf414b018ff81ce55a3f646b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89be7c09ebce4b7597643fddf5ac2c5f","placeholder":"​","style":"IPY_MODEL_08c4b3372b2247de822229cddc2175e4","value":"tokenizer.json: 100%"}},"e6248a34418342419a76a7890a8f74d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21d1d695d85a498193e807685b3d659c","placeholder":"​","style":"IPY_MODEL_bbc292ecfb4941a7869177f774b43a1a","value":"model.safetensors: 100%"}},"ef7b03d126564b66a0644bfd937aeac3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef8b68ae53724392b0f075cf4f9ad445":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0e8e94b3d254794a8f697922e256a73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b6d2978f4c413481ba47c2a4ec2bb0","placeholder":"​","style":"IPY_MODEL_c24ed5712a254bedb185b1a47159f056","value":"tokenizer.json: 100%"}},"f179040323834b8a82dd10283036e6da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31de05417254d68baae9567a0272df1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f360a218292348f4b6814bce5f353d47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6352bb5c22d74d5a943648793b01eccf","placeholder":"​","style":"IPY_MODEL_107fc1d57c554098b322b07013534152","value":"merges.txt: 100%"}},"f3ac39008ee74598a9b9826329ebde98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a56c904aa53347d496af04862be1748f","IPY_MODEL_4f880704aecb4ebbbaf696c97afed1cb","IPY_MODEL_08aa6a7467cf43db86b52c84af725447"],"layout":"IPY_MODEL_442d4495dfcf422dbd92873f1d4bf6d5"}},"f4339f891a3f474c8102a1827b48ab47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b70ac8c1d1154c84abc64256126e80b0","placeholder":"​","style":"IPY_MODEL_5e1a2f616c76479faf675e0d3abacbb5","value":"vocab.json: 100%"}},"f4b5d345ee994e848a106bbe78ccfc3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c11eee9c064a229c4292861a7cce8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ec49665e3445ccb04f89139f07a234":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4fd6031f51d4a94864b57b28c07610c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f684acff1ee8456c901b3534d8d1d3b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7f0f613881e44a1a5e79bf8dafe4d17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f91b4511e70f4ac498d1cefaa9d1b565":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98326afd2734c0c9d2cdc4c1aaddb03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff4714100f0f40f59587ef35aba8f451":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe8124e1bef4c29a3404077f87307ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
